{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(0, '/home/dfki/Desktop/Thesis/hyperopt')\n",
    "import temp\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import random\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK,Trials,trials_from_docs\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans,SpectralClustering\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21249"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load trial from openml\n",
    "trial_3 = pickle.load(open(\"/home/dfki/Desktop/Thesis/openml_test/pickel_files/3/trial_3.p\", \"rb\"))\n",
    "len(trial_3.trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(21249):\n",
    "    if len(trial_3.trials[i]['misc']['idxs']['pca__n_components'])>0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_trial = temp.find_n_initial(trial=trial_3,N=4000,good=15,bad=3987)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_31 = pickle.load(open(\"/home/dfki/Desktop/Thesis/openml_test/pickel_files/31/trial_31.p\", \"rb\"))\n",
    "len(trial_31.trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_trial = temp.remove_zero_trial(good_trial)\n",
    "len(good_trial.trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load trials from hyperopt history\n",
    "# all_trials = pickle.load(open(\"/home/dfki/Desktop/Thesis/hyperopt/result_openml/mylaptop/3/dima/3/10000it_0in_3.p\", \"rb\"))\n",
    "# trial_3 = temp.remove_zero_trial(all_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape vector is (21249, 63)\n",
      "(21249, 63)\n"
     ]
    }
   ],
   "source": [
    "X = temp.vector_builder(trial_3)\n",
    "# X = pickle.load(open(\"/home/dfki/Desktop/Thesis/hyperopt/result_openml/mylaptop/3/automatic/new/cluster/X_3.p\", \"rb\"))\n",
    "\n",
    "# XX=[]\n",
    "# for row in X:\n",
    "#     newrow = [float(ii)for ii in row]\n",
    "#     XX.append(newrow)\n",
    "# X  = np.array(XX)\n",
    "\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X)\n",
    "for i,a in enumerate(df.isnull().sum(axis = 0)):\n",
    "    print(i,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = trial_3.trials[0]['misc']['vals'].keys()\n",
    "\n",
    "df = pd.DataFrame(data=X, columns=features)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gradientboostingclassifier__n_iter_no_change'][20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_3.trials[20000]['misc']['vals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = StandardScaler().fit_transform(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(np.arange(500,6500,500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           data_index\n",
      "cluster_2            \n",
      "0               21189\n",
      "1                  60\n",
      "---------------------------------------\n",
      "           data_index  cluster_2\n",
      "cluster_3                       \n",
      "0               21138      21138\n",
      "1                  60         60\n",
      "2                  51         51\n",
      "---------------------------------------\n",
      "           data_index  cluster_2  cluster_3\n",
      "cluster_4                                  \n",
      "0               11305      11305      11305\n",
      "1                  60         60         60\n",
      "2                  51         51         51\n",
      "3                9833       9833       9833\n",
      "---------------------------------------\n",
      "           data_index  cluster_2  cluster_3  cluster_4\n",
      "cluster_5                                             \n",
      "0               11305      11305      11305      11305\n",
      "1                  60         60         60         60\n",
      "2                  51         51         51         51\n",
      "3                9767       9767       9767       9767\n",
      "4                  66         66         66         66\n",
      "---------------------------------------\n",
      "           data_index  cluster_2  cluster_3  cluster_4  cluster_5\n",
      "cluster_6                                                        \n",
      "0               11261      11261      11261      11261      11261\n",
      "1                  60         60         60         60         60\n",
      "2                  51         51         51         51         51\n",
      "3                9767       9767       9767       9767       9767\n",
      "4                  66         66         66         66         66\n",
      "5                  44         44         44         44         44\n",
      "---------------------------------------\n",
      "           data_index  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6\n",
      "cluster_7                                                                   \n",
      "0               11261      11261      11261      11261      11261      11261\n",
      "1                  60         60         60         60         60         60\n",
      "2                  51         51         51         51         51         51\n",
      "3                9766       9766       9766       9766       9766       9766\n",
      "4                  66         66         66         66         66         66\n",
      "5                  44         44         44         44         44         44\n",
      "6                   1          1          1          1          1          1\n",
      "---------------------------------------\n",
      "           data_index  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  \\\n",
      "cluster_8                                                                      \n",
      "0               11198      11198      11198      11198      11198      11198   \n",
      "1                  60         60         60         60         60         60   \n",
      "2                  51         51         51         51         51         51   \n",
      "3                9766       9766       9766       9766       9766       9766   \n",
      "4                  66         66         66         66         66         66   \n",
      "5                  44         44         44         44         44         44   \n",
      "6                   1          1          1          1          1          1   \n",
      "7                  63         63         63         63         63         63   \n",
      "\n",
      "           cluster_7  \n",
      "cluster_8             \n",
      "0              11198  \n",
      "1                 60  \n",
      "2                 51  \n",
      "3               9766  \n",
      "4                 66  \n",
      "5                 44  \n",
      "6                  1  \n",
      "7                 63  \n",
      "---------------------------------------\n",
      "           data_index  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  \\\n",
      "cluster_9                                                                      \n",
      "0               11127      11127      11127      11127      11127      11127   \n",
      "1                  60         60         60         60         60         60   \n",
      "2                  51         51         51         51         51         51   \n",
      "3                9766       9766       9766       9766       9766       9766   \n",
      "4                  66         66         66         66         66         66   \n",
      "5                  44         44         44         44         44         44   \n",
      "6                   1          1          1          1          1          1   \n",
      "7                  63         63         63         63         63         63   \n",
      "8                  71         71         71         71         71         71   \n",
      "\n",
      "           cluster_7  cluster_8  \n",
      "cluster_9                        \n",
      "0              11127      11127  \n",
      "1                 60         60  \n",
      "2                 51         51  \n",
      "3               9766       9766  \n",
      "4                 66         66  \n",
      "5                 44         44  \n",
      "6                  1          1  \n",
      "7                 63         63  \n",
      "8                 71         71  \n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#find the best K \n",
    "# Run the Kmeans algorithm and get the index of data points clusters\n",
    "sse = []\n",
    "list_k = list(range(2,10))\n",
    "cluster_map = pd.DataFrame()\n",
    "cluster_map['data_index'] = range(0,X.shape[0])\n",
    "\n",
    "for k in list_k:\n",
    "    km = KMeans(n_clusters=k, max_iter =1000)\n",
    "    km.fit(X)\n",
    "    sse.append(km.inertia_)\n",
    "    \n",
    "    cluster_map['cluster_{}'.format(k)] = km.labels_\n",
    "    print(cluster_map.groupby('cluster_{}'.format(k)).count())\n",
    "    print(\"---------------------------------------\")\n",
    "\n",
    "# Plot sse against k\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(list_k, sse, '-o')\n",
    "plt.xlabel(r'Number of clusters *k*')\n",
    "plt.ylabel('Sum of squared distance')\n",
    "plt.grid(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# function returns WSS score for k values from 1 to kmax\n",
    "def calculate_WSS(points, kmax):\n",
    "    sse = []\n",
    "    for k in range(1, kmax+1):\n",
    "        kmeans = KMeans(n_clusters = k).fit(points)\n",
    "        centroids = kmeans.cluster_centers_\n",
    "        pred_clusters = kmeans.predict(points)\n",
    "        curr_sse = 0\n",
    "    \n",
    "    # calculate square of Euclidean distance of each point from its cluster center and add to current WSS\n",
    "    for i in range(len(points)):\n",
    "        curr_center = centroids[pred_clusters[i]]\n",
    "        curr_sse += (points[i, 0] - curr_center[0]) ** 2 + (points[i, 1] - curr_center[1]) ** 2\n",
    "      \n",
    "    sse.append(curr_sse)\n",
    "    return sse\n",
    "sse= calculate_WSS(X,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(sse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204\n"
     ]
    }
   ],
   "source": [
    "def selecet_index_base_kmeans(X,k,min_member):\n",
    "    '''\n",
    "    X: np.array\n",
    "    k: number of k in kmeans\n",
    "    min_member: number of sample should take out of each cluster\n",
    "    '''\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0).fit(X)\n",
    "\n",
    "    cluster_map = pd.DataFrame()\n",
    "    cluster_map['data_index'] = range(0,X.shape[0])\n",
    "    cluster_map['cluster'] = kmeans.labels_\n",
    "\n",
    "    selected_index=[]\n",
    "    for i in range(k):\n",
    "        l = cluster_map[cluster_map.cluster == i].index\n",
    "        if len(l)<=min_member:\n",
    "            selected_index = list(l)+ list(selected_index)\n",
    "        else:\n",
    "            sampling = random.choices(l, k=min_member)\n",
    "            selected_index = list(selected_index) + list(sampling)\n",
    "        l=[]\n",
    "    \n",
    "    return selected_index\n",
    "    \n",
    "selected_index = selecet_index_base_kmeans(X,k=4,min_member=51)  \n",
    "print(len(selected_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204\n"
     ]
    }
   ],
   "source": [
    "trial3_basedkmeasn = temp.specialindex_trial_builder(trial_3,selected_index)\n",
    "print(len(trial3_basedkmeasn.trials))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the result\n",
    "pickle.dump(trial3_basedkmeasn, open('/home/dfki/Desktop/Thesis/hyperopt/result_openml/mylaptop/3/automatic/new/trials/trial204_k=3.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# investigate results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check the accuracy of each cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_3.trials[0]['result']['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans4 = KMeans(n_clusters=30, random_state=0).fit(X)\n",
    "cluster_kmeans4 = pd.DataFrame()\n",
    "cluster_kmeans4['data_index'] = range(0,X.shape[0])\n",
    "cluster_kmeans4['cluster'] = kmeans4.labels_\n",
    "cluster_kmeans4['acc'] = range(0,X.shape[0])\n",
    "acc=[]\n",
    "for index, eachtrial in enumerate(trial_3.trials):\n",
    "#     print(index,abs(eachtrial['result']['loss']))\n",
    "    acc.append(abs(eachtrial['result']['loss']))\n",
    "    \n",
    "cluster_kmeans4['acc'] = acc\n",
    "cluster_kmeans4.head()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sse[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    l = cluster_kmeans4[cluster_kmeans4.cluster == i]\n",
    "    l_index = cluster_kmeans4[cluster_kmeans4.cluster == i].index\n",
    "    print(l['acc'].mean())\n",
    "    print(len(l_index))\n",
    "    print(\"%%%%%%%%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_kmeans4['acc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.where(0 == cluster_kmeans4[cluster_kmeans4['acc']<0.5]['cluster'])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_kmeans4['acc'][1556]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans4.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_trial = temp.find_n_initial(trial=trial_3,N=4000,good=15,bad=3987)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_loss=good_trial.losses()\n",
    "losses = [abs(i) for i in good_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_loss=trial_3.losses()\n",
    "all_losses = [abs(i) for i in all_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### histogram the best History sofar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "counts, edges, plot = plt.hist(all_losses, bins=5)\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('N - points')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage=[]\n",
    "for number in counts:\n",
    "    percentage.append((number/21249)*100)\n",
    "percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = np.array(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_points(a):\n",
    "    a=np.array(a)\n",
    "    print(a.mean())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "stats.binned_statistic(losses, statistic=select_points, bins=5, values=losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(good_trial.losses()).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = temp.vector_builder(good_trial)\n",
    "X = np.array(good_trial)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.47778473091364204"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_trial.trials[290]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i,xx in enumerate(X):\n",
    "    if(xx[0]==0.47778473091364204):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data  # we only take the first two features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "principalComponents = pca.fit_transform(X)\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['component1', 'component2'])\n",
    "a = principalDf.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(a[:,0],a[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "# Data for a three-dimensional line\n",
    "zline = principalDf['component1']\n",
    "xline = principalDf['component2']\n",
    "yline = principalDf['component3']\n",
    "ax.plot3D(xline, yline, zline, 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as sch\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 20\n",
    "fig_size[1] = 8\n",
    "\n",
    "dendegram = sch.dendrogram(sch.linkage(X,method='ward'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc = AgglomerativeClustering(n_clusters=4,affinity='euclidean',linkage='ward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hc = hc.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import somoclu\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "som = somoclu.Somoclu(80,4000, data=X)\n",
    "%time som.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "som.view_component_planes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimalK(data, nrefs=3, maxClusters=15):\n",
    "    \"\"\"\n",
    "    Calculates KMeans optimal K using Gap Statistic from Tibshirani, Walther, Hastie\n",
    "    Params:\n",
    "        data: ndarry of shape (n_samples, n_features)\n",
    "        nrefs: number of sample reference datasets to create\n",
    "        maxClusters: Maximum number of clusters to test for\n",
    "    Returns: (gaps, optimalK)\n",
    "    \"\"\"\n",
    "    gaps = np.zeros((len(range(1, maxClusters)),))\n",
    "    resultsdf = pd.DataFrame({'clusterCount':[], 'gap':[]})\n",
    "    for gap_index, k in enumerate(range(1, maxClusters)):\n",
    "\n",
    "        # Holder for reference dispersion results\n",
    "        refDisps = np.zeros(nrefs)\n",
    "\n",
    "        # For n references, generate random sample and perform kmeans getting resulting dispersion of each loop\n",
    "        for i in range(nrefs):\n",
    "            \n",
    "            # Create new random reference set\n",
    "            randomReference = np.random.random_sample(size=data.shape)\n",
    "            \n",
    "            # Fit to it\n",
    "            km = KMeans(k)\n",
    "            km.fit(randomReference)\n",
    "            \n",
    "            refDisp = km.inertia_\n",
    "            refDisps[i] = refDisp\n",
    "\n",
    "        # Fit cluster to original data and create dispersion\n",
    "        km = KMeans(k)\n",
    "        km.fit(data)\n",
    "        \n",
    "        origDisp = km.inertia_\n",
    "\n",
    "        # Calculate gap statistic\n",
    "        gap = np.log(np.mean(refDisps)) - np.log(origDisp)\n",
    "\n",
    "        # Assign this loop's gap statistic to gaps\n",
    "        gaps[gap_index] = gap\n",
    "        \n",
    "        resultsdf = resultsdf.append({'clusterCount':k, 'gap':gap}, ignore_index=True)\n",
    "\n",
    "    return (gaps.argmax() + 1, resultsdf)  # Plus 1 because index of 0 means 1 cluster is optimal, index 2 = 3 clusters are optimal\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k, gapdf = optimalK(X, nrefs=10, maxClusters=10)\n",
    "print ('Optimal k is: ', k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the best K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# estimate number of clusters with the gap statistic\n",
    "from what_the_cluster.GapStat import GapStat\n",
    "gs = GapStat(clusterer='kmeans',  # an arbitrary clustering algorithm can be provided\n",
    "         cluster_sizes=range(1, 10),\n",
    "         ref_dist='uniform',  # either 'uniform' or 'svd'\n",
    "         B=10)  # number of samples from the reference null distribution\n",
    "\n",
    "gs.fit(X)\n",
    "gs.plot_wcss_curves()\n",
    "gs.plot_gap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Silhouette Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "all_sil_coeff =[]\n",
    "for n_cluster in range(2, 11):\n",
    "    kmeans = KMeans(n_clusters=n_cluster).fit(X)\n",
    "    label = kmeans.labels_\n",
    "    sil_coeff = silhouette_score(X, label, metric='euclidean')\n",
    "    all_sil_coeff.append(sil_coeff)\n",
    "    print(\"For n_clusters={}, The Silhouette Coefficient is {}\".format(n_cluster, sil_coeff))\n",
    "plt.plot(all_sil_coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = 16, 8\n",
    "\n",
    "def draw_ellipse(position, covariance, ax=None, **kwargs):\n",
    "    \"\"\"Draw an ellipse with a given position and covariance\"\"\"\n",
    "    ax = ax or plt.gca()\n",
    "    # Convert covariance to principal axes\n",
    "    if covariance.shape == (2, 2):\n",
    "        U, s, Vt = np.linalg.svd(covariance)\n",
    "        angle = np.degrees(np.arctan2(U[1, 0], U[0, 0]))\n",
    "        width, height = 2 * np.sqrt(s)\n",
    "    else:\n",
    "        angle = 0\n",
    "        width, height = 2 * np.sqrt(covariance)\n",
    "    \n",
    "    # Draw the Ellipse\n",
    "    for nsig in range(1, 4):\n",
    "        ax.add_patch(Ellipse(position, nsig * width, nsig * height,\n",
    "                             angle, **kwargs))\n",
    "        \n",
    "def plot_gmm(gmm, X, label=True, ax=None):\n",
    "    ax = ax or plt.gca()\n",
    "    labels = gmm.fit(X).predict(X)\n",
    "    if label:\n",
    "        ax.scatter(X[:, 0], X[:, 1], c=labels, s=40, cmap='viridis', zorder=2)\n",
    "    else:\n",
    "        ax.scatter(X[:, 0], X[:, 1], s=40, zorder=2)\n",
    "    \n",
    "    w_factor = 0.2 / gmm.weights_.max()\n",
    "    for pos, covar, w in zip(gmm.means_, gmm.covariances_, gmm.weights_):\n",
    "        draw_ellipse(pos, covar, alpha=w * w_factor)\n",
    "    plt.title(\"GMM with %d components\"%len(gmm.means_), fontsize=(20))\n",
    "    plt.xlabel(\"U.A.\")\n",
    "    plt.ylabel(\"U.A.\")\n",
    "def SelBest(arr:list, X:int)->list:\n",
    "    '''\n",
    "    returns the set of X configurations with shorter distance\n",
    "    '''\n",
    "    dx=np.argsort(arr)[:X]\n",
    "    return arr[dx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters=np.arange(2, 10)\n",
    "sils=[]\n",
    "sils_err=[]\n",
    "iterations=20\n",
    "for n in n_clusters:\n",
    "    tmp_sil=[]\n",
    "    for _ in range(iterations):\n",
    "        gmm=GMM(n, n_init=2).fit(embeddings) \n",
    "        labels=gmm.predict(embeddings)\n",
    "        sil=metrics.silhouette_score(embeddings, labels, metric='euclidean')\n",
    "        tmp_sil.append(sil)\n",
    "    val=np.mean(SelBest(np.array(tmp_sil), int(iterations/5)))\n",
    "    err=np.std(tmp_sil)\n",
    "    sils.append(val)\n",
    "    sils_err.append(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(n_clusters, sils, yerr=sils_err)\n",
    "plt.title(\"Silhouette Scores\", fontsize=20)\n",
    "plt.xticks(n_clusters)\n",
    "plt.xlabel(\"N. of clusters\")\n",
    "plt.ylabel(\"Score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BIC Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bics=[]\n",
    "bics_err=[]\n",
    "iterations=20\n",
    "for n in n_clusters:\n",
    "    tmp_bic=[]\n",
    "    for _ in range(iterations):\n",
    "        gmm=GMM(n, n_init=2).fit(embeddings) \n",
    "        \n",
    "        tmp_bic.append(gmm.bic(embeddings))\n",
    "    val=np.mean(SelBest(np.array(tmp_bic), int(iterations/5)))\n",
    "    err=np.std(tmp_bic)\n",
    "    bics.append(val)\n",
    "    bics_err.append(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(n_clusters,bics, yerr=bics_err, label='BIC')\n",
    "plt.title(\"BIC Scores\", fontsize=20)\n",
    "plt.xticks(n_clusters)\n",
    "plt.xlabel(\"N. of clusters\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find the nearst point to centroid in kmeasn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Compute DBSCAN\n",
    "db = DBSCAN(eps=0.3, min_samples=10).fit(X)\n",
    "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True\n",
    "labels = db.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_clusters_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_map = pd.DataFrame()\n",
    "cluster_map['data_index'] = range(0,X.shape[0])\n",
    "cluster_map['cluster'] = db.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(cluster_map['cluster']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = cluster_map.groupby('cluster').count()\n",
    "print(list(types))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selecet_index_base_DBSCAN(X,min_member):\n",
    "    '''\n",
    "    X: np.array\n",
    "    k: number of k in kmeans\n",
    "    min_member: number of sample should take out of each cluster\n",
    "    '''\n",
    "    # Compute DBSCAN\n",
    "    db = DBSCAN(eps=0.3, min_samples=min_member).fit(X)\n",
    "    core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "    core_samples_mask[db.core_sample_indices_] = True\n",
    "    labels = db.labels_\n",
    "\n",
    "\n",
    "    # Number of clusters in labels, ignoring noise if present.\n",
    "    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    n_noise_ = list(labels).count(-1)\n",
    "    \n",
    "    print (\"Number of Cluster is {}\".format(print(n_clusters_)))\n",
    "\n",
    "\n",
    "    cluster_map = pd.DataFrame()\n",
    "    cluster_map['data_index'] = range(0,X.shape[0])\n",
    "    cluster_map['cluster'] = db.labels_\n",
    "\n",
    "    selected_index=[]\n",
    "    for i in list(set(cluster_map['cluster'])):\n",
    "        l = cluster_map[cluster_map.cluster == i].index\n",
    "        if len(l)<=min_member:\n",
    "            selected_index = list(l)+ list(selected_index)\n",
    "        else:\n",
    "            sampling = random.choices(l, k=min_member)\n",
    "            selected_index = list(selected_index) + list(sampling)\n",
    "        l=[]\n",
    "    \n",
    "    return selected_index\n",
    "    \n",
    "selected_index = selecet_index_base_DBSCAN(X,min_member=10)  \n",
    "print(len(selected_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial3_basedDBSACN = temp.specialindex_trial_builder(trial_3,selected_index)\n",
    "print(len(trial3_basedDBSACN.trials))\n",
    "\n",
    "#save the result\n",
    "pickle.dump(trial3_basedDBSACN, open('/home/dfki/Desktop/Thesis/hyperopt/result_openml/mylaptop/3/automatic/new/trials/trial3_940in_basedDBSACN_k=93.p', 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_3 = 79.84\n",
    "dataset_3_history = 83.99 #21249 history \n",
    "\n",
    "dataset_3_kmeansopenml_history = 71.90 #153 history \n",
    "dataset_3_153_random = 77.49 #5 times run\n",
    "\n",
    "dataset_3_kmeanshyperopt_history =81.74 # 240 history\n",
    "dataset_3_240random = 75.39 #5 times run \n",
    "\n",
    "dataframe = {'Dataset':[3],\n",
    "             'Null_History':[dataset_3],\n",
    "             'With_full_History':[dataset_3_history],\n",
    "             'kmeans_openml_History':[dataset_3_kmeansopenml_history],\n",
    "             'kmeans_openml_random':[dataset_3_153_random],\n",
    "             'kmeans_hyperopt_History':[dataset_3_kmeanshyperopt_history],\n",
    "             'kmeans_hyperopt_random':[dataset_3_240random]\n",
    "             \n",
    "            }\n",
    "\n",
    "dataframe_1 = pd.DataFrame(dataframe)\n",
    "\n",
    "dataframe_2 = pd.melt(dataframe_1, id_vars=\"Dataset\", var_name=\"Approaches\", value_name=\"Avg_Accuracies\")\n",
    "dataframe_2.head()\n",
    "\n",
    "sns.set(font_scale=1.5,style='whitegrid')\n",
    "# sns.set_context(\"talk\",font_scale=1.4,rc={'figure.figsize':(11.7,15)} )\n",
    "\n",
    "g= sns.catplot(x='Dataset', y='Avg_Accuracies', hue='Approaches', data=dataframe_2, kind='bar',aspect=2)\n",
    "g.set(ylim=(60,95))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the best epsilon for DBscan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import DBSCAN\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = NearestNeighbors(n_neighbors=2)\n",
    "nbrs = neigh.fit(X)\n",
    "distances, indices = nbrs.kneighbors(X)\n",
    "\n",
    "distances = np.sort(distances, axis=0)\n",
    "distances = distances[:,1]\n",
    "\n",
    "# print(distances)\n",
    "# print(indices)\n",
    "plt.plot(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = distances[np.where(np.sort(distances)<25)]\n",
    "plt.plot(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=1, random_state=0).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center_a = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "s = [20, 15, 27, 30]\n",
    "heapq.nsmallest(2,[i for i, k in enumerate(s)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_a=[]\n",
    "for row in X:\n",
    "    distance_a.append(scipy.spatial.distance.euclidean(center_a, row))\n",
    "np.argsort(distance_a)[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(distance_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "A = np.array([1, 7, 9, 2, 0.1, 17, 17, 1.5])\n",
    "np.argsort(A)[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def cluster_DBSCAN(X_1,min_member=20):\n",
    "    '''\n",
    "    X: np.array\n",
    "    k: number of k in kmeans\n",
    "    min_member: number of sample should take out of each cluster\n",
    "    '''\n",
    "    # Compute DBSCAN\n",
    "    db = DBSCAN(eps=50, min_samples=min_member).fit(X_1)\n",
    "    core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "    core_samples_mask[db.core_sample_indices_] = True\n",
    "    labels = db.labels_\n",
    "\n",
    "\n",
    "    # Number of clusters in labels, ignoring noise if present.\n",
    "    #n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    \n",
    "    #keep the outlier\n",
    "    n_clusters_ = len(set(labels))\n",
    "    n_noise_ = list(labels).count(-1)\n",
    "   \n",
    "    print (\"N cluster is {}\".format(n_clusters_))\n",
    "    return n_clusters_\n",
    "\n",
    "\n",
    "\n",
    "def objective(args):\n",
    "    a,b,c,d,e = args\n",
    "    \n",
    "    print(a,b,c,d,e)\n",
    "    print(\"-------------\")\n",
    "    N_a = int(a * 86)\n",
    "    N_b = int(b * 139)\n",
    "    N_c = int(c * 2519)\n",
    "    N_d = int(d * 522)\n",
    "    N_e = int(e * 17983)\n",
    "    \n",
    "    list_a = list(np.where((X[:,0]>0) & (X[:,0]<0.2))[0])\n",
    "    list_b = list(np.where((X[:,0]>0.2) & (X[:,0]<0.4))[0])\n",
    "    list_c = list(np.where((X[:,0]>0.4) & (X[:,0]<0.6))[0])\n",
    "    list_d = list(np.where((X[:,0]>0.6) & (X[:,0]<0.8))[0])\n",
    "    list_e = list(np.where((X[:,0]>0.8) & (X[:,0]<0.999))[0])\n",
    "    \n",
    "#     print(len(list_a),len(list_b),len(list_c),len(list_d),len(list_e))\n",
    "    \n",
    "    random.seed(0)\n",
    "\n",
    "\n",
    "    def sampling1(list_a,N_a):      \n",
    "        X_a= X[list_a,:]\n",
    "        kmeans_a = KMeans(n_clusters=1, random_state=0).fit(X_a)\n",
    "        center_a = kmeans_a.cluster_centers_\n",
    "        distance_a=[]\n",
    "        for rows in X_a:\n",
    "            distance_a.append(scipy.spatial.distance.euclidean(center_a, rows))\n",
    "        sampling_a = np.argsort(distance_a)[:N_a]\n",
    "        return sampling_a\n",
    "    \n",
    "    sampling_a = sampling1(list_a,min(N_a,len(list_a)))\n",
    "    sampling_b = sampling1(list_b,min(N_b,len(list_b)))\n",
    "    sampling_c = sampling1(list_c,min(N_c,len(list_c)))\n",
    "    sampling_d = sampling1(list_d,min(N_d,len(list_d)))\n",
    "    sampling_e = sampling1(list_e,min(N_e,len(list_e)))\n",
    "    \n",
    "    \n",
    "    sampling_all = list(sampling_a)+list(sampling_b)+list(sampling_c)+list(sampling_d)+list(sampling_e)\n",
    "\n",
    "    \n",
    "    new_x = X[sampling_all,:]\n",
    "    \n",
    "    print(new_x.shape)\n",
    "    \n",
    "    n_cluster = cluster_DBSCAN(new_x)\n",
    "    \n",
    "    Deduction = n_cluster/len(sampling_all)\n",
    "    \n",
    "    print(\"Deduction is {}\".format(Deduction))\n",
    "    print(\"^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\")\n",
    "    \n",
    "    \n",
    "    return {'loss': -Deduction, 'status': STATUS_OK,'index':sampling_all }\n",
    "\n",
    "\n",
    "space  = [hp.uniform('a',0,1),\n",
    "         hp.uniform('b',0,1),\n",
    "         hp.uniform('c',0,1),\n",
    "         hp.uniform('d',0,1),\n",
    "         hp.uniform('e',0,1)]\n",
    "\n",
    "\n",
    "trial = Trials()\n",
    "\n",
    "\n",
    "best,trials_new = fmin(objective,\n",
    "    space=space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=100,\n",
    "    trials=trial,\n",
    "    rstate=np.random.RandomState(10),)\n",
    "\n",
    "print(best)\n",
    "best_indexes = trials_new.best_trial['result']['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(best_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_base_maxkasr = temp.sepecialindex_trial_builder(trial_3,best_indexes)\n",
    "pickle.dump(trial_base_maxkasr, open('/home/dfki/Desktop/Thesis/hyperopt/result_openml/mylaptop/3/automatic/new/trials/trial_base_maxkasr1049.p','wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iteration in list(np.arange(2000,11000,2000)):\n",
    "    trials_1 = vector.trial_builder_kmeans(trial_3,num_clusters=iteration)\n",
    "    print(trials_1.trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cluster_map = pd.DataFrame()\n",
    "cluster_map['data_index'] = []\n",
    "\n",
    "cluster_map.loc[0,'data_index'] = 0\n",
    "\n",
    "cluster_map.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "iris = load_iris()\n",
    "\n",
    "X = pd.DataFrame(iris.data, columns=iris['feature_names'])\n",
    "\n",
    "\n",
    "sse = []\n",
    "list_k = list(range(2,10))\n",
    "cluster_map = pd.DataFrame()\n",
    "cluster_map['data_index'] = range(0,X.shape[0])\n",
    "\n",
    "for k in list_k:\n",
    "    km = KMeans(n_clusters=k)\n",
    "    km.fit(X)\n",
    "    sse.append(km.inertia_)\n",
    "    \n",
    "    cluster_map['cluster_{}'.format(k)] = km.labels_\n",
    "#     print(cluster_map.groupby('cluster_{}'.format(k)).count())\n",
    "#     print(\"---------------------------------------\")\n",
    "\n",
    "# Plot sse against k\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(list_k, sse, '-o')\n",
    "plt.xlabel(r'Number of clusters *k*')\n",
    "plt.ylabel('Sum of squared distance')\n",
    "plt.grid(True)\n",
    "print(sse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "iris = load_iris()\n",
    "X = pd.DataFrame(iris.data, columns=iris['feature_names'])\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "sse = []\n",
    "list_k = list(range(2,10))\n",
    "cluster_map = pd.DataFrame()\n",
    "cluster_map['data_index'] = range(0,X.shape[0])\n",
    "\n",
    "for k in list_k:\n",
    "    km = KMeans(n_clusters=k)\n",
    "    km.fit(X)\n",
    "    sse.append(km.inertia_)\n",
    "    \n",
    "    cluster_map['cluster_{}'.format(k)] = km.labels_\n",
    "#     print(cluster_map.groupby('cluster_{}'.format(k)).count())\n",
    "#     print(\"---------------------------------------\")\n",
    "\n",
    "# Plot sse against k\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(list_k, sse, '-o')\n",
    "plt.xlabel(r'Number of clusters *k*')\n",
    "plt.ylabel('Sum of squared distance')\n",
    "plt.grid(True)\n",
    "print(sse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withoutscaling = [152.34795176035792, 78.85144142614601, 57.228473214285714, 46.44618205128205, 41.704424470266574, 34.40900974025974, 30.01588095238096, 27.894012189564823]\n",
    "scaling = [222.36170496502308, 140.0327527742865, 114.30480331856761, 90.80759161913358, 81.72775255799205, 71.81371300822669, 62.647183903468985, 54.29894572818739]\n",
    "\n",
    "for x,y in zip(withoutscaling,scaling):\n",
    "    print(x/y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features.\n",
    "y = iris.target\n",
    "\n",
    "\n",
    "# To getter a better understanding of interaction of the dimensions\n",
    "# plot the first three PCA dimensions\n",
    "fig = plt.figure(1, figsize=(8, 6))\n",
    "ax = Axes3D(fig, elev=-150, azim=110)\n",
    "X_reduced = PCA(n_components=3).fit_transform(iris.data)\n",
    "ax.scatter(X_reduced[:, 0], X_reduced[:, 1], X_reduced[:, 2], c=y,\n",
    "           cmap=plt.cm.Set1, edgecolor='k', s=40)\n",
    "ax.set_title(\"First three PCA directions\")\n",
    "ax.set_xlabel(\"1st eigenvector\")\n",
    "ax.w_xaxis.set_ticklabels([])\n",
    "ax.set_ylabel(\"2nd eigenvector\")\n",
    "ax.w_yaxis.set_ticklabels([])\n",
    "ax.set_zlabel(\"3rd eigenvector\")\n",
    "ax.w_zaxis.set_ticklabels([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features.\n",
    "X = StandardScaler().fit_transform(X)\n",
    "y = iris.target\n",
    "\n",
    "\n",
    "\n",
    "# To getter a better understanding of interaction of the dimensions\n",
    "# plot the first three PCA dimensions\n",
    "XX = iris.data\n",
    "# XX = StandardScaler().fit_transform(XX)\n",
    "fig = plt.figure(1, figsize=(8, 6))\n",
    "ax = Axes3D(fig, elev=-150, azim=110)\n",
    "\n",
    "\n",
    "X_reduced = PCA(n_components=2).fit_transform(XX)\n",
    "\n",
    "ax.scatter(X_reduced[:,0],X_reduced[:,1])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= np.array([[None,2,None],[3,4,None],[None,None,None]])\n",
    "df = pd.DataFrame(a)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis='columns',how='all')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in X:\n",
    "    if None in X:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(a[:,:]==np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    df[col].fillna(df[col].mean(),inplace=True)\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nan == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To calculate mean use imputer class\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values= None, strategy='mean')\n",
    "imputer = imputer.fit(X[:, 1:3])\n",
    "X[:, 1:3] = imputer.transform(X[:, 1:3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
