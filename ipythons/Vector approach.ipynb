{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(0, '/home/dfki/Desktop/Thesis/hyperopt')\n",
    "import temp\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import random\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK,Trials,trials_from_docs\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans,SpectralClustering\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21945"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load trial from openml\n",
    "trial_3 = pickle.load(open(\"/home/dfki/Desktop/Thesis/openml_test/pickel_files/3/trial_3_new.p\", \"rb\"))\n",
    "len(trial_3.trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_trial = temp.find_n_initial(trial=trial_3,N=4000,good=15,bad=3987)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(good_trial, open('/home/dfki/Desktop/Thesis/openml_test/pickel_files/4000in_trial3.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_31 = pickle.load(open(\"/home/dfki/Desktop/Thesis/openml_test/pickel_files/31/trial_31.p\", \"rb\"))\n",
    "len(trial_31.trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_trial = temp.remove_zero_trial(good_trial)\n",
    "len(good_trial.trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load trials from hyperopt history\n",
    "# all_trials = pickle.load(open(\"/home/dfki/Desktop/Thesis/hyperopt/result_openml/mylaptop/3/dima/3/10000it_0in_3.p\", \"rb\"))\n",
    "# trial_3 = temp.remove_zero_trial(all_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "b\n"
     ]
    }
   ],
   "source": [
    "a={'a':1,'b':2}\n",
    "for i in a.keys():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "points3 = pickle.load(open(\"/home/dfki/Desktop/Thesis/openml_test/pickel_files/31/trial_31_withrunid.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>flow_id</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>data_preprocessing</th>\n",
       "      <th>classifier</th>\n",
       "      <th>decisiontreeclassifier__criterion</th>\n",
       "      <th>decisiontreeclassifier__max_depth</th>\n",
       "      <th>decisiontreeclassifier__min_samples_leaf</th>\n",
       "      <th>decisiontreeclassifier__min_samples_split</th>\n",
       "      <th>ColumnTransformer__remainder</th>\n",
       "      <th>...</th>\n",
       "      <th>mlpclassifier__nesterovs_momentum</th>\n",
       "      <th>mlpclassifier__power_t</th>\n",
       "      <th>mlpclassifier__shuffle</th>\n",
       "      <th>mlpclassifier__solver</th>\n",
       "      <th>mlpclassifier__tol</th>\n",
       "      <th>sgdclassifier__loss</th>\n",
       "      <th>sgdclassifier__penalty</th>\n",
       "      <th>sgdclassifier__alpha</th>\n",
       "      <th>sgdclassifier__max_iter</th>\n",
       "      <th>sgdclassifier__tol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3807068</td>\n",
       "      <td>6840</td>\n",
       "      <td>0.700</td>\n",
       "      <td>SimpleImputer</td>\n",
       "      <td>decisiontreeclassifier</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.280163</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>...</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3809199</td>\n",
       "      <td>6840</td>\n",
       "      <td>0.700</td>\n",
       "      <td>SimpleImputer</td>\n",
       "      <td>decisiontreeclassifier</td>\n",
       "      <td>entropy</td>\n",
       "      <td>1.24742</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>...</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3809243</td>\n",
       "      <td>6840</td>\n",
       "      <td>0.700</td>\n",
       "      <td>SimpleImputer</td>\n",
       "      <td>decisiontreeclassifier</td>\n",
       "      <td>gini</td>\n",
       "      <td>0.626198</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>...</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3809448</td>\n",
       "      <td>6840</td>\n",
       "      <td>0.700</td>\n",
       "      <td>SimpleImputer</td>\n",
       "      <td>decisiontreeclassifier</td>\n",
       "      <td>gini</td>\n",
       "      <td>0.757525</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>...</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3811787</td>\n",
       "      <td>6840</td>\n",
       "      <td>0.700</td>\n",
       "      <td>SimpleImputer</td>\n",
       "      <td>decisiontreeclassifier</td>\n",
       "      <td>entropy</td>\n",
       "      <td>1.34644</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>...</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4828</th>\n",
       "      <td>9851345</td>\n",
       "      <td>8817</td>\n",
       "      <td>0.647</td>\n",
       "      <td>ColumnTransformer</td>\n",
       "      <td>svc</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>...</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4829</th>\n",
       "      <td>9851509</td>\n",
       "      <td>8817</td>\n",
       "      <td>0.655</td>\n",
       "      <td>ColumnTransformer</td>\n",
       "      <td>svc</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>...</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4830</th>\n",
       "      <td>9851547</td>\n",
       "      <td>8817</td>\n",
       "      <td>0.746</td>\n",
       "      <td>ColumnTransformer</td>\n",
       "      <td>svc</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>...</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4831</th>\n",
       "      <td>9851611</td>\n",
       "      <td>8817</td>\n",
       "      <td>0.749</td>\n",
       "      <td>ColumnTransformer</td>\n",
       "      <td>svc</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>...</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4832</th>\n",
       "      <td>9851676</td>\n",
       "      <td>8817</td>\n",
       "      <td>0.700</td>\n",
       "      <td>ColumnTransformer</td>\n",
       "      <td>svc</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>...</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "      <td>This_is_None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4833 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       run_id  flow_id  accuracy data_preprocessing              classifier  \\\n",
       "0     3807068     6840     0.700      SimpleImputer  decisiontreeclassifier   \n",
       "1     3809199     6840     0.700      SimpleImputer  decisiontreeclassifier   \n",
       "2     3809243     6840     0.700      SimpleImputer  decisiontreeclassifier   \n",
       "3     3809448     6840     0.700      SimpleImputer  decisiontreeclassifier   \n",
       "4     3811787     6840     0.700      SimpleImputer  decisiontreeclassifier   \n",
       "...       ...      ...       ...                ...                     ...   \n",
       "4828  9851345     8817     0.647  ColumnTransformer                     svc   \n",
       "4829  9851509     8817     0.655  ColumnTransformer                     svc   \n",
       "4830  9851547     8817     0.746  ColumnTransformer                     svc   \n",
       "4831  9851611     8817     0.749  ColumnTransformer                     svc   \n",
       "4832  9851676     8817     0.700  ColumnTransformer                     svc   \n",
       "\n",
       "     decisiontreeclassifier__criterion decisiontreeclassifier__max_depth  \\\n",
       "0                              entropy                          0.280163   \n",
       "1                              entropy                           1.24742   \n",
       "2                                 gini                          0.626198   \n",
       "3                                 gini                          0.757525   \n",
       "4                              entropy                           1.34644   \n",
       "...                                ...                               ...   \n",
       "4828                      This_is_None                      This_is_None   \n",
       "4829                      This_is_None                      This_is_None   \n",
       "4830                      This_is_None                      This_is_None   \n",
       "4831                      This_is_None                      This_is_None   \n",
       "4832                      This_is_None                      This_is_None   \n",
       "\n",
       "     decisiontreeclassifier__min_samples_leaf  \\\n",
       "0                                          18   \n",
       "1                                          15   \n",
       "2                                          16   \n",
       "3                                          10   \n",
       "4                                          20   \n",
       "...                                       ...   \n",
       "4828                             This_is_None   \n",
       "4829                             This_is_None   \n",
       "4830                             This_is_None   \n",
       "4831                             This_is_None   \n",
       "4832                             This_is_None   \n",
       "\n",
       "     decisiontreeclassifier__min_samples_split ColumnTransformer__remainder  \\\n",
       "0                                           16                 This_is_None   \n",
       "1                                            6                 This_is_None   \n",
       "2                                            5                 This_is_None   \n",
       "3                                           19                 This_is_None   \n",
       "4                                           15                 This_is_None   \n",
       "...                                        ...                          ...   \n",
       "4828                              This_is_None                  passthrough   \n",
       "4829                              This_is_None                  passthrough   \n",
       "4830                              This_is_None                  passthrough   \n",
       "4831                              This_is_None                  passthrough   \n",
       "4832                              This_is_None                  passthrough   \n",
       "\n",
       "      ... mlpclassifier__nesterovs_momentum mlpclassifier__power_t  \\\n",
       "0     ...                      This_is_None           This_is_None   \n",
       "1     ...                      This_is_None           This_is_None   \n",
       "2     ...                      This_is_None           This_is_None   \n",
       "3     ...                      This_is_None           This_is_None   \n",
       "4     ...                      This_is_None           This_is_None   \n",
       "...   ...                               ...                    ...   \n",
       "4828  ...                      This_is_None           This_is_None   \n",
       "4829  ...                      This_is_None           This_is_None   \n",
       "4830  ...                      This_is_None           This_is_None   \n",
       "4831  ...                      This_is_None           This_is_None   \n",
       "4832  ...                      This_is_None           This_is_None   \n",
       "\n",
       "     mlpclassifier__shuffle mlpclassifier__solver mlpclassifier__tol  \\\n",
       "0              This_is_None          This_is_None       This_is_None   \n",
       "1              This_is_None          This_is_None       This_is_None   \n",
       "2              This_is_None          This_is_None       This_is_None   \n",
       "3              This_is_None          This_is_None       This_is_None   \n",
       "4              This_is_None          This_is_None       This_is_None   \n",
       "...                     ...                   ...                ...   \n",
       "4828           This_is_None          This_is_None       This_is_None   \n",
       "4829           This_is_None          This_is_None       This_is_None   \n",
       "4830           This_is_None          This_is_None       This_is_None   \n",
       "4831           This_is_None          This_is_None       This_is_None   \n",
       "4832           This_is_None          This_is_None       This_is_None   \n",
       "\n",
       "     sgdclassifier__loss sgdclassifier__penalty sgdclassifier__alpha  \\\n",
       "0           This_is_None           This_is_None         This_is_None   \n",
       "1           This_is_None           This_is_None         This_is_None   \n",
       "2           This_is_None           This_is_None         This_is_None   \n",
       "3           This_is_None           This_is_None         This_is_None   \n",
       "4           This_is_None           This_is_None         This_is_None   \n",
       "...                  ...                    ...                  ...   \n",
       "4828        This_is_None           This_is_None         This_is_None   \n",
       "4829        This_is_None           This_is_None         This_is_None   \n",
       "4830        This_is_None           This_is_None         This_is_None   \n",
       "4831        This_is_None           This_is_None         This_is_None   \n",
       "4832        This_is_None           This_is_None         This_is_None   \n",
       "\n",
       "     sgdclassifier__max_iter sgdclassifier__tol  \n",
       "0               This_is_None       This_is_None  \n",
       "1               This_is_None       This_is_None  \n",
       "2               This_is_None       This_is_None  \n",
       "3               This_is_None       This_is_None  \n",
       "4               This_is_None       This_is_None  \n",
       "...                      ...                ...  \n",
       "4828            This_is_None       This_is_None  \n",
       "4829            This_is_None       This_is_None  \n",
       "4830            This_is_None       This_is_None  \n",
       "4831            This_is_None       This_is_None  \n",
       "4832            This_is_None       This_is_None  \n",
       "\n",
       "[4833 rows x 82 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_31 = pickle.load(open(\"/home/dfki/Desktop/Thesis/openml_test/pickel_files/31/df_31.p\", \"rb\"))\n",
    "df_31.head(4833)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_31.to_csv('df.csv', index=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9851676\n",
      "8817\n",
      "0.7\n",
      "ColumnTransformer\n",
      "svc\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "passthrough\n",
      "VarianceThreshold\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "0\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "0.9898916645211513\n",
      "0\n",
      "3\n",
      "0.001979748132997962\n",
      "rbf\n",
      "True\n",
      "0.0006861177675046171\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n",
      "This_is_None\n"
     ]
    }
   ],
   "source": [
    "for col in df_31.columns:\n",
    "#     print(col)\n",
    "    print(df_31.loc[4832,col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': 2,\n",
       " 'tid': 0,\n",
       " 'spec': None,\n",
       " 'result': {'loss': -0.7, 'status': 'ok', 'run_id': 3807068},\n",
       " 'misc': {'tid': 0,\n",
       "  'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "  'workdir': None,\n",
       "  'idxs': {'run_id': [0],\n",
       "   'data_preprocessing': [0],\n",
       "   'classifier': [0],\n",
       "   'decisiontreeclassifier__criterion': [0],\n",
       "   'decisiontreeclassifier__max_depth': [0],\n",
       "   'decisiontreeclassifier__min_samples_leaf': [0],\n",
       "   'decisiontreeclassifier__min_samples_split': [0],\n",
       "   'ColumnTransformer__remainder': [],\n",
       "   'feature_preprocessing': [0],\n",
       "   'pca__iterated_power': [],\n",
       "   'pca__n_components': [],\n",
       "   'pca__svd_solver': [],\n",
       "   'pca__tol': [],\n",
       "   'pca__whiten': [],\n",
       "   'kernelpca__kernel': [],\n",
       "   'kernelpca__n_components': [],\n",
       "   'VarianceThreshold__threshold': [],\n",
       "   'randomforestclassifier__criterion': [],\n",
       "   'randomforestclassifier__max_depth': [],\n",
       "   'randomforestclassifier__min_samples_leaf': [],\n",
       "   'randomforestclassifier__min_samples_split': [],\n",
       "   'randomforestclassifier__min_weight_fraction_leaf': [],\n",
       "   'randomforestclassifier__max_features': [],\n",
       "   'randomforestclassifier__n_estimators': [],\n",
       "   'randomforestclassifier__oob_score': [],\n",
       "   'gradientboostingclassifier__criterion': [],\n",
       "   'gradientboostingclassifier__learning_rate': [],\n",
       "   'gradientboostingclassifier__max_depth': [],\n",
       "   'gradientboostingclassifier__max_features': [],\n",
       "   'gradientboostingclassifier__min_impurity_decrease': [],\n",
       "   'gradientboostingclassifier__min_samples_leaf': [],\n",
       "   'gradientboostingclassifier__min_samples_split': [],\n",
       "   'gradientboostingclassifier__min_weight_fraction_leaf': [],\n",
       "   'gradientboostingclassifier__n_estimators': [],\n",
       "   'gradientboostingclassifier__n_iter_no_change': [],\n",
       "   'gradientboostingclassifier__subsample': [],\n",
       "   'gradientboostingclassifier__tol': [],\n",
       "   'gradientboostingclassifier__validation_fraction': [],\n",
       "   'bernoullinb__fit_prior': [],\n",
       "   'bernoullinb__alpha': [],\n",
       "   'fkceigenpro__degree': [],\n",
       "   'fkceigenpro__gamma': [],\n",
       "   'fkceigenpro__kernel': [],\n",
       "   'fkceigenpro__n_components': [],\n",
       "   'svc__C': [],\n",
       "   'svc__coef0': [],\n",
       "   'svc__degree': [],\n",
       "   'svc__gamma': [],\n",
       "   'svc__kernel': [],\n",
       "   'svc__shrinking': [],\n",
       "   'svc__tol': [],\n",
       "   'kneighborsClassifier__n_neighbors': [],\n",
       "   'kneighborsClassifier__algorithm': [],\n",
       "   'extratreesclassifier__bootstrap': [],\n",
       "   'extratreesclassifier__criterion': [],\n",
       "   'extratreesclassifier__max_features': [],\n",
       "   'extratreesclassifier__min_samples_leaf': [],\n",
       "   'extratreesclassifier__min_samples_split': [],\n",
       "   'mlpclassifier__activation': [],\n",
       "   'mlpclassifier__alpha': [],\n",
       "   'mlpclassifier__batch_size': [],\n",
       "   'mlpclassifier__beta_1': [],\n",
       "   'mlpclassifier__beta_2': [],\n",
       "   'mlpclassifier__early_stopping': [],\n",
       "   'mlpclassifier__hidden_layer_sizes': [],\n",
       "   'mlpclassifier__learning_rate': [],\n",
       "   'mlpclassifier__learning_rate_init': [],\n",
       "   'mlpclassifier__max_iter': [],\n",
       "   'mlpclassifier__momentum': [],\n",
       "   'mlpclassifier__n_iter_no_change': [],\n",
       "   'mlpclassifier__nesterovs_momentum': [],\n",
       "   'mlpclassifier__power_t': [],\n",
       "   'mlpclassifier__shuffle': [],\n",
       "   'mlpclassifier__solver': [],\n",
       "   'mlpclassifier__tol': [],\n",
       "   'sgdclassifier__loss': [],\n",
       "   'sgdclassifier__penalty': [],\n",
       "   'sgdclassifier__alpha': [],\n",
       "   'sgdclassifier__max_iter': [],\n",
       "   'sgdclassifier__tol': []},\n",
       "  'vals': {'run_id': [3807068],\n",
       "   'data_preprocessing': [1],\n",
       "   'classifier': [1],\n",
       "   'decisiontreeclassifier__criterion': [1],\n",
       "   'decisiontreeclassifier__max_depth': [0.2801630246326896],\n",
       "   'decisiontreeclassifier__min_samples_leaf': [17],\n",
       "   'decisiontreeclassifier__min_samples_split': [15],\n",
       "   'ColumnTransformer__remainder': [],\n",
       "   'feature_preprocessing': [3],\n",
       "   'pca__iterated_power': [],\n",
       "   'pca__n_components': [],\n",
       "   'pca__svd_solver': [],\n",
       "   'pca__tol': [],\n",
       "   'pca__whiten': [],\n",
       "   'kernelpca__kernel': [],\n",
       "   'kernelpca__n_components': [],\n",
       "   'VarianceThreshold__threshold': [],\n",
       "   'randomforestclassifier__criterion': [],\n",
       "   'randomforestclassifier__max_depth': [],\n",
       "   'randomforestclassifier__min_samples_leaf': [],\n",
       "   'randomforestclassifier__min_samples_split': [],\n",
       "   'randomforestclassifier__min_weight_fraction_leaf': [],\n",
       "   'randomforestclassifier__max_features': [],\n",
       "   'randomforestclassifier__n_estimators': [],\n",
       "   'randomforestclassifier__oob_score': [],\n",
       "   'gradientboostingclassifier__criterion': [],\n",
       "   'gradientboostingclassifier__learning_rate': [],\n",
       "   'gradientboostingclassifier__max_depth': [],\n",
       "   'gradientboostingclassifier__max_features': [],\n",
       "   'gradientboostingclassifier__min_impurity_decrease': [],\n",
       "   'gradientboostingclassifier__min_samples_leaf': [],\n",
       "   'gradientboostingclassifier__min_samples_split': [],\n",
       "   'gradientboostingclassifier__min_weight_fraction_leaf': [],\n",
       "   'gradientboostingclassifier__n_estimators': [],\n",
       "   'gradientboostingclassifier__n_iter_no_change': [],\n",
       "   'gradientboostingclassifier__subsample': [],\n",
       "   'gradientboostingclassifier__tol': [],\n",
       "   'gradientboostingclassifier__validation_fraction': [],\n",
       "   'bernoullinb__fit_prior': [],\n",
       "   'bernoullinb__alpha': [],\n",
       "   'fkceigenpro__degree': [],\n",
       "   'fkceigenpro__gamma': [],\n",
       "   'fkceigenpro__kernel': [],\n",
       "   'fkceigenpro__n_components': [],\n",
       "   'svc__C': [],\n",
       "   'svc__coef0': [],\n",
       "   'svc__degree': [],\n",
       "   'svc__gamma': [],\n",
       "   'svc__kernel': [],\n",
       "   'svc__shrinking': [],\n",
       "   'svc__tol': [],\n",
       "   'kneighborsClassifier__n_neighbors': [],\n",
       "   'kneighborsClassifier__algorithm': [],\n",
       "   'extratreesclassifier__bootstrap': [],\n",
       "   'extratreesclassifier__criterion': [],\n",
       "   'extratreesclassifier__max_features': [],\n",
       "   'extratreesclassifier__min_samples_leaf': [],\n",
       "   'extratreesclassifier__min_samples_split': [],\n",
       "   'mlpclassifier__activation': [],\n",
       "   'mlpclassifier__alpha': [],\n",
       "   'mlpclassifier__batch_size': [],\n",
       "   'mlpclassifier__beta_1': [],\n",
       "   'mlpclassifier__beta_2': [],\n",
       "   'mlpclassifier__early_stopping': [],\n",
       "   'mlpclassifier__hidden_layer_sizes': [],\n",
       "   'mlpclassifier__learning_rate': [],\n",
       "   'mlpclassifier__learning_rate_init': [],\n",
       "   'mlpclassifier__max_iter': [],\n",
       "   'mlpclassifier__momentum': [],\n",
       "   'mlpclassifier__n_iter_no_change': [],\n",
       "   'mlpclassifier__nesterovs_momentum': [],\n",
       "   'mlpclassifier__power_t': [],\n",
       "   'mlpclassifier__shuffle': [],\n",
       "   'mlpclassifier__solver': [],\n",
       "   'mlpclassifier__tol': [],\n",
       "   'sgdclassifier__loss': [],\n",
       "   'sgdclassifier__penalty': [],\n",
       "   'sgdclassifier__alpha': [],\n",
       "   'sgdclassifier__max_iter': [],\n",
       "   'sgdclassifier__tol': []}},\n",
       " 'exp_key': None,\n",
       " 'owner': None,\n",
       " 'version': 0,\n",
       " 'book_time': None,\n",
       " 'refresh_time': None}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points3.trials[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def points_to_dataframe(points):\n",
    "    d={}\n",
    "    for ii in points[0]:\n",
    "        d[ii] =[]\n",
    "    \n",
    "    for dictinary in points:\n",
    "        for key in dictinary:\n",
    "            if dictinary[key] == 'This_is_None':\n",
    "                d[key].append(np.nan)\n",
    "            else:\n",
    "                d[key].append(dictinary[key])\n",
    "    df = pd.DataFrame.from_dict(d)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>classifier</th>\n",
       "      <th>randomforestclassifier__criterion</th>\n",
       "      <th>randomforestclassifier__max_depth</th>\n",
       "      <th>randomforestclassifier__min_samples_leaf</th>\n",
       "      <th>randomforestclassifier__min_samples_split</th>\n",
       "      <th>randomforestclassifier__min_weight_fraction_leaf</th>\n",
       "      <th>randomforestclassifier__max_features</th>\n",
       "      <th>randomforestclassifier__n_estimators</th>\n",
       "      <th>randomforestclassifier__oob_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mlpclassifier__nesterovs_momentum</th>\n",
       "      <th>mlpclassifier__power_t</th>\n",
       "      <th>mlpclassifier__shuffle</th>\n",
       "      <th>mlpclassifier__solver</th>\n",
       "      <th>mlpclassifier__tol</th>\n",
       "      <th>sgdclassifier__loss</th>\n",
       "      <th>sgdclassifier__penalty</th>\n",
       "      <th>sgdclassifier__alpha</th>\n",
       "      <th>sgdclassifier__max_iter</th>\n",
       "      <th>sgdclassifier__tol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.980288</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>490.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.979349</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>490.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.979975</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>490.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.979975</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>490.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.981227</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>490.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21940</th>\n",
       "      <td>0.997184</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21941</th>\n",
       "      <td>0.993742</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21942</th>\n",
       "      <td>0.907384</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>0.522215</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>0.995620</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21945 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       accuracy  classifier  randomforestclassifier__criterion  \\\n",
       "0      0.980288           0                                0.0   \n",
       "1      0.979349           0                                0.0   \n",
       "2      0.979975           0                                0.0   \n",
       "3      0.979975           0                                0.0   \n",
       "4      0.981227           0                                0.0   \n",
       "...         ...         ...                                ...   \n",
       "21940  0.997184           5                                NaN   \n",
       "21941  0.993742           5                                NaN   \n",
       "21942  0.907384           5                                NaN   \n",
       "21943  0.522215           5                                NaN   \n",
       "21944  0.995620           5                                NaN   \n",
       "\n",
       "       randomforestclassifier__max_depth  \\\n",
       "0                                    0.0   \n",
       "1                                    0.0   \n",
       "2                                    0.0   \n",
       "3                                    0.0   \n",
       "4                                    0.0   \n",
       "...                                  ...   \n",
       "21940                                NaN   \n",
       "21941                                NaN   \n",
       "21942                                NaN   \n",
       "21943                                NaN   \n",
       "21944                                NaN   \n",
       "\n",
       "       randomforestclassifier__min_samples_leaf  \\\n",
       "0                                           0.0   \n",
       "1                                           0.0   \n",
       "2                                           0.0   \n",
       "3                                           0.0   \n",
       "4                                           0.0   \n",
       "...                                         ...   \n",
       "21940                                       NaN   \n",
       "21941                                       NaN   \n",
       "21942                                       NaN   \n",
       "21943                                       NaN   \n",
       "21944                                       NaN   \n",
       "\n",
       "       randomforestclassifier__min_samples_split  \\\n",
       "0                                            0.0   \n",
       "1                                            0.0   \n",
       "2                                            0.0   \n",
       "3                                            0.0   \n",
       "4                                            0.0   \n",
       "...                                          ...   \n",
       "21940                                        NaN   \n",
       "21941                                        NaN   \n",
       "21942                                        NaN   \n",
       "21943                                        NaN   \n",
       "21944                                        NaN   \n",
       "\n",
       "       randomforestclassifier__min_weight_fraction_leaf  \\\n",
       "0                                                   0.0   \n",
       "1                                                   0.0   \n",
       "2                                                   0.0   \n",
       "3                                                   0.0   \n",
       "4                                                   0.0   \n",
       "...                                                 ...   \n",
       "21940                                               NaN   \n",
       "21941                                               NaN   \n",
       "21942                                               NaN   \n",
       "21943                                               NaN   \n",
       "21944                                               NaN   \n",
       "\n",
       "       randomforestclassifier__max_features  \\\n",
       "0                                       NaN   \n",
       "1                                       NaN   \n",
       "2                                       NaN   \n",
       "3                                       NaN   \n",
       "4                                       NaN   \n",
       "...                                     ...   \n",
       "21940                                   NaN   \n",
       "21941                                   NaN   \n",
       "21942                                   NaN   \n",
       "21943                                   NaN   \n",
       "21944                                   NaN   \n",
       "\n",
       "       randomforestclassifier__n_estimators  \\\n",
       "0                                     490.0   \n",
       "1                                     490.0   \n",
       "2                                     490.0   \n",
       "3                                     490.0   \n",
       "4                                     490.0   \n",
       "...                                     ...   \n",
       "21940                                   NaN   \n",
       "21941                                   NaN   \n",
       "21942                                   NaN   \n",
       "21943                                   NaN   \n",
       "21944                                   NaN   \n",
       "\n",
       "       randomforestclassifier__oob_score  ...  \\\n",
       "0                                    1.0  ...   \n",
       "1                                    1.0  ...   \n",
       "2                                    1.0  ...   \n",
       "3                                    1.0  ...   \n",
       "4                                    1.0  ...   \n",
       "...                                  ...  ...   \n",
       "21940                                NaN  ...   \n",
       "21941                                NaN  ...   \n",
       "21942                                NaN  ...   \n",
       "21943                                NaN  ...   \n",
       "21944                                NaN  ...   \n",
       "\n",
       "       mlpclassifier__nesterovs_momentum  mlpclassifier__power_t  \\\n",
       "0                                    NaN                     NaN   \n",
       "1                                    NaN                     NaN   \n",
       "2                                    NaN                     NaN   \n",
       "3                                    NaN                     NaN   \n",
       "4                                    NaN                     NaN   \n",
       "...                                  ...                     ...   \n",
       "21940                                NaN                     NaN   \n",
       "21941                                NaN                     NaN   \n",
       "21942                                NaN                     NaN   \n",
       "21943                                NaN                     NaN   \n",
       "21944                                NaN                     NaN   \n",
       "\n",
       "       mlpclassifier__shuffle  mlpclassifier__solver  mlpclassifier__tol  \\\n",
       "0                         NaN                    NaN                 NaN   \n",
       "1                         NaN                    NaN                 NaN   \n",
       "2                         NaN                    NaN                 NaN   \n",
       "3                         NaN                    NaN                 NaN   \n",
       "4                         NaN                    NaN                 NaN   \n",
       "...                       ...                    ...                 ...   \n",
       "21940                     NaN                    NaN                 NaN   \n",
       "21941                     NaN                    NaN                 NaN   \n",
       "21942                     NaN                    NaN                 NaN   \n",
       "21943                     NaN                    NaN                 NaN   \n",
       "21944                     NaN                    NaN                 NaN   \n",
       "\n",
       "       sgdclassifier__loss  sgdclassifier__penalty  sgdclassifier__alpha  \\\n",
       "0                      NaN                     NaN                   NaN   \n",
       "1                      NaN                     NaN                   NaN   \n",
       "2                      NaN                     NaN                   NaN   \n",
       "3                      NaN                     NaN                   NaN   \n",
       "4                      NaN                     NaN                   NaN   \n",
       "...                    ...                     ...                   ...   \n",
       "21940                  NaN                     NaN                   NaN   \n",
       "21941                  NaN                     NaN                   NaN   \n",
       "21942                  NaN                     NaN                   NaN   \n",
       "21943                  NaN                     NaN                   NaN   \n",
       "21944                  NaN                     NaN                   NaN   \n",
       "\n",
       "       sgdclassifier__max_iter  sgdclassifier__tol  \n",
       "0                          NaN                 NaN  \n",
       "1                          NaN                 NaN  \n",
       "2                          NaN                 NaN  \n",
       "3                          NaN                 NaN  \n",
       "4                          NaN                 NaN  \n",
       "...                        ...                 ...  \n",
       "21940                      NaN                 NaN  \n",
       "21941                      NaN                 NaN  \n",
       "21942                      NaN                 NaN  \n",
       "21943                      NaN                 NaN  \n",
       "21944                      NaN                 NaN  \n",
       "\n",
       "[21945 rows x 80 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_to_dataframe(points3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.980288,\n",
       " 'classifier': 0,\n",
       " 'randomforestclassifier__criterion': 0,\n",
       " 'randomforestclassifier__max_depth': 0,\n",
       " 'randomforestclassifier__min_samples_leaf': 0,\n",
       " 'randomforestclassifier__min_samples_split': 0,\n",
       " 'randomforestclassifier__min_weight_fraction_leaf': 0.0,\n",
       " 'randomforestclassifier__max_features': 'This_is_None',\n",
       " 'randomforestclassifier__n_estimators': 490,\n",
       " 'randomforestclassifier__oob_score': 1,\n",
       " 'feature_preprocessing': 1,\n",
       " 'pca__iterated_power': 0,\n",
       " 'pca__n_components': 0,\n",
       " 'pca__svd_solver': 0,\n",
       " 'pca__tol': 0.0,\n",
       " 'pca__whiten': 1,\n",
       " 'data_preprocessing': 5,\n",
       " 'ColumnTransformer__remainder': 'This_is_None',\n",
       " 'kernelpca__kernel': 'This_is_None',\n",
       " 'kernelpca__n_components': 'This_is_None',\n",
       " 'VarianceThreshold__threshold': 'This_is_None',\n",
       " 'decisiontreeclassifier__criterion': 'This_is_None',\n",
       " 'decisiontreeclassifier__max_depth': 'This_is_None',\n",
       " 'decisiontreeclassifier__min_samples_leaf': 'This_is_None',\n",
       " 'decisiontreeclassifier__min_samples_split': 'This_is_None',\n",
       " 'gradientboostingclassifier__criterion': 'This_is_None',\n",
       " 'gradientboostingclassifier__learning_rate': 'This_is_None',\n",
       " 'gradientboostingclassifier__max_depth': 'This_is_None',\n",
       " 'gradientboostingclassifier__max_features': 'This_is_None',\n",
       " 'gradientboostingclassifier__min_impurity_decrease': 'This_is_None',\n",
       " 'gradientboostingclassifier__min_samples_leaf': 'This_is_None',\n",
       " 'gradientboostingclassifier__min_samples_split': 'This_is_None',\n",
       " 'gradientboostingclassifier__min_weight_fraction_leaf': 'This_is_None',\n",
       " 'gradientboostingclassifier__n_estimators': 'This_is_None',\n",
       " 'gradientboostingclassifier__n_iter_no_change': 'This_is_None',\n",
       " 'gradientboostingclassifier__subsample': 'This_is_None',\n",
       " 'gradientboostingclassifier__tol': 'This_is_None',\n",
       " 'gradientboostingclassifier__validation_fraction': 'This_is_None',\n",
       " 'bernoullinb__fit_prior': 'This_is_None',\n",
       " 'bernoullinb__alpha': 'This_is_None',\n",
       " 'fkceigenpro__degree': 'This_is_None',\n",
       " 'fkceigenpro__gamma': 'This_is_None',\n",
       " 'fkceigenpro__kernel': 'This_is_None',\n",
       " 'fkceigenpro__n_components': 'This_is_None',\n",
       " 'svc__C': 'This_is_None',\n",
       " 'svc__coef0': 'This_is_None',\n",
       " 'svc__degree': 'This_is_None',\n",
       " 'svc__gamma': 'This_is_None',\n",
       " 'svc__kernel': 'This_is_None',\n",
       " 'svc__shrinking': 'This_is_None',\n",
       " 'svc__tol': 'This_is_None',\n",
       " 'kneighborsClassifier__n_neighbors': 'This_is_None',\n",
       " 'kneighborsClassifier__algorithm': 'This_is_None',\n",
       " 'extratreesclassifier__bootstrap': 'This_is_None',\n",
       " 'extratreesclassifier__criterion': 'This_is_None',\n",
       " 'extratreesclassifier__max_features': 'This_is_None',\n",
       " 'extratreesclassifier__min_samples_leaf': 'This_is_None',\n",
       " 'extratreesclassifier__min_samples_split': 'This_is_None',\n",
       " 'mlpclassifier__activation': 'This_is_None',\n",
       " 'mlpclassifier__alpha': 'This_is_None',\n",
       " 'mlpclassifier__batch_size': 'This_is_None',\n",
       " 'mlpclassifier__beta_1': 'This_is_None',\n",
       " 'mlpclassifier__beta_2': 'This_is_None',\n",
       " 'mlpclassifier__early_stopping': 'This_is_None',\n",
       " 'mlpclassifier__hidden_layer_sizes': 'This_is_None',\n",
       " 'mlpclassifier__learning_rate': 'This_is_None',\n",
       " 'mlpclassifier__learning_rate_init': 'This_is_None',\n",
       " 'mlpclassifier__max_iter': 'This_is_None',\n",
       " 'mlpclassifier__momentum': 'This_is_None',\n",
       " 'mlpclassifier__n_iter_no_change': 'This_is_None',\n",
       " 'mlpclassifier__nesterovs_momentum': 'This_is_None',\n",
       " 'mlpclassifier__power_t': 'This_is_None',\n",
       " 'mlpclassifier__shuffle': 'This_is_None',\n",
       " 'mlpclassifier__solver': 'This_is_None',\n",
       " 'mlpclassifier__tol': 'This_is_None',\n",
       " 'sgdclassifier__loss': 'This_is_None',\n",
       " 'sgdclassifier__penalty': 'This_is_None',\n",
       " 'sgdclassifier__alpha': 'This_is_None',\n",
       " 'sgdclassifier__max_iter': 'This_is_None',\n",
       " 'sgdclassifier__tol': 'This_is_None'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_builder(trial):\n",
    "\n",
    "\n",
    "    features = trial.trials[0]['misc']['vals'].keys()\n",
    "    d={}\n",
    "    # d['acc'] = []\n",
    "    for ii in features:\n",
    "        d[ii] =[]\n",
    "\n",
    "\n",
    "    for index, each_trial in enumerate(trial.trials):\n",
    "        # d['acc'].append(abs(each_trial['result']['loss']))\n",
    "        for i, x in enumerate(each_trial['misc']['vals']):\n",
    "\n",
    "            if len(each_trial['misc']['vals'][x]) == 0:\n",
    "#                 d[x].append(0.0)\n",
    "                d[x].append(np.nan)\n",
    "            else:\n",
    "                if str(each_trial['misc']['vals'][x][0]) in ['None',np.nan]:\n",
    "                    d[x].append(np.nan)\n",
    "#                     d[x].append(0.0)\n",
    "                else:\n",
    "                    d[x].append(float(each_trial['misc']['vals'][x][0]))\n",
    "\n",
    "    df = pd.DataFrame.from_dict(d)\n",
    "    #fill the None value with the mean of the column\n",
    "    \n",
    "    return df\n",
    "\n",
    "#     df = df.fillna(df.mean())\n",
    "\n",
    "#     df1 = df.dropna(axis='columns', how='all')\n",
    "#     vector = df1.values\n",
    "    \n",
    "    #     print(list(df1.columns) \n",
    "    #     print(list(df.columns) )\n",
    "#     print('shape vector is {}'.format(vector.shape))\n",
    "#     print(set(df.columns)-set(df1.columns))\n",
    "#     return vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape vector is (21945, 79)\n"
     ]
    }
   ],
   "source": [
    "X = temp.vector_builder(trial_3)\n",
    "# print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>randomforestclassifier__criterion</th>\n",
       "      <th>randomforestclassifier__max_depth</th>\n",
       "      <th>randomforestclassifier__min_samples_leaf</th>\n",
       "      <th>randomforestclassifier__min_samples_split</th>\n",
       "      <th>randomforestclassifier__min_weight_fraction_leaf</th>\n",
       "      <th>randomforestclassifier__max_features</th>\n",
       "      <th>randomforestclassifier__n_estimators</th>\n",
       "      <th>randomforestclassifier__oob_score</th>\n",
       "      <th>feature_preprocessing</th>\n",
       "      <th>...</th>\n",
       "      <th>mlpclassifier__nesterovs_momentum</th>\n",
       "      <th>mlpclassifier__power_t</th>\n",
       "      <th>mlpclassifier__shuffle</th>\n",
       "      <th>mlpclassifier__solver</th>\n",
       "      <th>mlpclassifier__tol</th>\n",
       "      <th>sgdclassifier__loss</th>\n",
       "      <th>sgdclassifier__penalty</th>\n",
       "      <th>sgdclassifier__alpha</th>\n",
       "      <th>sgdclassifier__max_iter</th>\n",
       "      <th>sgdclassifier__tol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>490.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>490.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>490.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>490.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>490.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   classifier  randomforestclassifier__criterion  \\\n",
       "0         0.0                                0.0   \n",
       "1         0.0                                0.0   \n",
       "2         0.0                                0.0   \n",
       "3         0.0                                0.0   \n",
       "4         0.0                                0.0   \n",
       "\n",
       "   randomforestclassifier__max_depth  \\\n",
       "0                                0.0   \n",
       "1                                0.0   \n",
       "2                                0.0   \n",
       "3                                0.0   \n",
       "4                                0.0   \n",
       "\n",
       "   randomforestclassifier__min_samples_leaf  \\\n",
       "0                                       0.0   \n",
       "1                                       0.0   \n",
       "2                                       0.0   \n",
       "3                                       0.0   \n",
       "4                                       0.0   \n",
       "\n",
       "   randomforestclassifier__min_samples_split  \\\n",
       "0                                        0.0   \n",
       "1                                        0.0   \n",
       "2                                        0.0   \n",
       "3                                        0.0   \n",
       "4                                        0.0   \n",
       "\n",
       "   randomforestclassifier__min_weight_fraction_leaf  \\\n",
       "0                                               0.0   \n",
       "1                                               0.0   \n",
       "2                                               0.0   \n",
       "3                                               0.0   \n",
       "4                                               0.0   \n",
       "\n",
       "   randomforestclassifier__max_features  randomforestclassifier__n_estimators  \\\n",
       "0                                   NaN                                 490.0   \n",
       "1                                   NaN                                 490.0   \n",
       "2                                   NaN                                 490.0   \n",
       "3                                   NaN                                 490.0   \n",
       "4                                   NaN                                 490.0   \n",
       "\n",
       "   randomforestclassifier__oob_score  feature_preprocessing  ...  \\\n",
       "0                                1.0                    1.0  ...   \n",
       "1                                1.0                    1.0  ...   \n",
       "2                                1.0                    1.0  ...   \n",
       "3                                1.0                    1.0  ...   \n",
       "4                                1.0                    1.0  ...   \n",
       "\n",
       "   mlpclassifier__nesterovs_momentum  mlpclassifier__power_t  \\\n",
       "0                                NaN                     NaN   \n",
       "1                                NaN                     NaN   \n",
       "2                                NaN                     NaN   \n",
       "3                                NaN                     NaN   \n",
       "4                                NaN                     NaN   \n",
       "\n",
       "   mlpclassifier__shuffle  mlpclassifier__solver  mlpclassifier__tol  \\\n",
       "0                     NaN                    NaN                 NaN   \n",
       "1                     NaN                    NaN                 NaN   \n",
       "2                     NaN                    NaN                 NaN   \n",
       "3                     NaN                    NaN                 NaN   \n",
       "4                     NaN                    NaN                 NaN   \n",
       "\n",
       "   sgdclassifier__loss  sgdclassifier__penalty  sgdclassifier__alpha  \\\n",
       "0                  NaN                     NaN                   NaN   \n",
       "1                  NaN                     NaN                   NaN   \n",
       "2                  NaN                     NaN                   NaN   \n",
       "3                  NaN                     NaN                   NaN   \n",
       "4                  NaN                     NaN                   NaN   \n",
       "\n",
       "   sgdclassifier__max_iter  sgdclassifier__tol  \n",
       "0                      NaN                 NaN  \n",
       "1                      NaN                 NaN  \n",
       "2                      NaN                 NaN  \n",
       "3                      NaN                 NaN  \n",
       "4                      NaN                 NaN  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X)\n",
    "for i,a in enumerate(df.isnull().sum(axis = 0)):\n",
    "    print(i,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = trial_3.trials[0]['misc']['vals'].keys()\n",
    "\n",
    "df = pd.DataFrame(data=X, columns=features)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21945, 79)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = StandardScaler().fit_transform(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(np.arange(500,6500,500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           data_index\n",
      "cluster_2            \n",
      "0               21885\n",
      "1                  60\n",
      "---------------------------------------\n",
      "           data_index  cluster_2\n",
      "cluster_3                       \n",
      "0               21834      21834\n",
      "1                  60         60\n",
      "2                  51         51\n",
      "---------------------------------------\n",
      "           data_index  cluster_2  cluster_3\n",
      "cluster_4                                  \n",
      "0               21768      21768      21768\n",
      "1                  60         60         60\n",
      "2                  51         51         51\n",
      "3                  66         66         66\n",
      "---------------------------------------\n",
      "           data_index  cluster_2  cluster_3  cluster_4\n",
      "cluster_5                                             \n",
      "0               21724      21724      21724      21724\n",
      "1                  60         60         60         60\n",
      "2                  51         51         51         51\n",
      "3                  66         66         66         66\n",
      "4                  44         44         44         44\n",
      "---------------------------------------\n",
      "           data_index  cluster_2  cluster_3  cluster_4  cluster_5\n",
      "cluster_6                                                        \n",
      "0               21723      21723      21723      21723      21723\n",
      "1                  60         60         60         60         60\n",
      "2                  51         51         51         51         51\n",
      "3                  66         66         66         66         66\n",
      "4                  44         44         44         44         44\n",
      "5                   1          1          1          1          1\n",
      "---------------------------------------\n",
      "           data_index  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6\n",
      "cluster_7                                                                   \n",
      "0               21660      21660      21660      21660      21660      21660\n",
      "1                  60         60         60         60         60         60\n",
      "2                  51         51         51         51         51         51\n",
      "3                  66         66         66         66         66         66\n",
      "4                  44         44         44         44         44         44\n",
      "5                   1          1          1          1          1          1\n",
      "6                  63         63         63         63         63         63\n",
      "---------------------------------------\n",
      "           data_index  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  \\\n",
      "cluster_8                                                                      \n",
      "0               21589      21589      21589      21589      21589      21589   \n",
      "1                  60         60         60         60         60         60   \n",
      "2                  51         51         51         51         51         51   \n",
      "3                  66         66         66         66         66         66   \n",
      "4                  44         44         44         44         44         44   \n",
      "5                   1          1          1          1          1          1   \n",
      "6                  63         63         63         63         63         63   \n",
      "7                  71         71         71         71         71         71   \n",
      "\n",
      "           cluster_7  \n",
      "cluster_8             \n",
      "0              21589  \n",
      "1                 60  \n",
      "2                 51  \n",
      "3                 66  \n",
      "4                 44  \n",
      "5                  1  \n",
      "6                 63  \n",
      "7                 71  \n",
      "---------------------------------------\n",
      "           data_index  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  \\\n",
      "cluster_9                                                                      \n",
      "0               21515      21515      21515      21515      21515      21515   \n",
      "1                  60         60         60         60         60         60   \n",
      "2                  51         51         51         51         51         51   \n",
      "3                  66         66         66         66         66         66   \n",
      "4                  44         44         44         44         44         44   \n",
      "5                   1          1          1          1          1          1   \n",
      "6                  63         63         63         63         63         63   \n",
      "7                  71         71         71         71         71         71   \n",
      "8                  74         74         74         74         74         74   \n",
      "\n",
      "           cluster_7  cluster_8  \n",
      "cluster_9                        \n",
      "0              21515      21515  \n",
      "1                 60         60  \n",
      "2                 51         51  \n",
      "3                 66         66  \n",
      "4                 44         44  \n",
      "5                  1          1  \n",
      "6                 63         63  \n",
      "7                 71         71  \n",
      "8                 74         74  \n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#find the best K \n",
    "# Run the Kmeans algorithm and get the index of data points clusters\n",
    "sse = []\n",
    "list_k = list(range(2,10))\n",
    "cluster_map = pd.DataFrame()\n",
    "cluster_map['data_index'] = range(0,X.shape[0])\n",
    "\n",
    "for k in list_k:\n",
    "    km = KMeans(n_clusters=k, max_iter =1000)\n",
    "    km.fit(X)\n",
    "    sse.append(km.inertia_)\n",
    "    \n",
    "    cluster_map['cluster_{}'.format(k)] = km.labels_\n",
    "    print(cluster_map.groupby('cluster_{}'.format(k)).count())\n",
    "    print(\"---------------------------------------\")\n",
    "\n",
    "# Plot sse against k\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(list_k, sse, '-o')\n",
    "plt.xlabel(r'Number of clusters *k*')\n",
    "plt.ylabel('Sum of squared distance')\n",
    "plt.grid(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# function returns WSS score for k values from 1 to kmax\n",
    "def calculate_WSS(points, kmax):\n",
    "    sse = []\n",
    "    for k in range(1, kmax+1):\n",
    "        kmeans = KMeans(n_clusters = k).fit(points)\n",
    "        centroids = kmeans.cluster_centers_\n",
    "        pred_clusters = kmeans.predict(points)\n",
    "        curr_sse = 0\n",
    "    \n",
    "    # calculate square of Euclidean distance of each point from its cluster center and add to current WSS\n",
    "    for i in range(len(points)):\n",
    "        curr_center = centroids[pred_clusters[i]]\n",
    "        curr_sse += (points[i, 0] - curr_center[0]) ** 2 + (points[i, 1] - curr_center[1]) ** 2\n",
    "      \n",
    "    sse.append(curr_sse)\n",
    "    return sse\n",
    "sse= calculate_WSS(X,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(sse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selecet_index_base_kmeans(X,k,min_member):\n",
    "    '''\n",
    "    X: np.array\n",
    "    k: number of k in kmeans\n",
    "    min_member: number of sample should take out of each cluster\n",
    "    '''\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0).fit(X)\n",
    "\n",
    "    cluster_map = pd.DataFrame()\n",
    "    cluster_map['data_index'] = range(0,X.shape[0])\n",
    "    cluster_map['cluster'] = kmeans.labels_\n",
    "\n",
    "    selected_index=[]\n",
    "    for i in range(k):\n",
    "        l = cluster_map[cluster_map.cluster == i].index\n",
    "        if len(l)<=min_member:\n",
    "            selected_index = list(l)+ list(selected_index)\n",
    "        else:\n",
    "            sampling = random.choices(l, k=min_member)\n",
    "            selected_index = list(selected_index) + list(sampling)\n",
    "        l=[]\n",
    "    \n",
    "    return selected_index\n",
    "    \n",
    "selected_index = selecet_index_base_kmeans(X,k=4,min_member=51)  \n",
    "print(len(selected_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial3_basedkmeasn = temp.specialindex_trial_builder(trial_3,selected_index)\n",
    "print(len(trial3_basedkmeasn.trials))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the result\n",
    "pickle.dump(good_trial, open('/home/dfki/Desktop/Thesis/hyperopt/result_openml/mylaptop/3/automatic/new/trials/4000in_new.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# investigate results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check the accuracy of each cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_3.trials[0]['result']['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans4 = KMeans(n_clusters=8, random_state=0).fit(X)\n",
    "cluster_kmeans4 = pd.DataFrame()\n",
    "cluster_kmeans4['data_index'] = range(0,X.shape[0])\n",
    "cluster_kmeans4['cluster'] = kmeans4.labels_\n",
    "cluster_kmeans4['acc'] = range(0,X.shape[0])\n",
    "acc=[]\n",
    "for index, eachtrial in enumerate(trial_3.trials):\n",
    "    if index ==22105:\n",
    "        break\n",
    "    acc.append(abs(eachtrial['result']['loss']))\n",
    "\n",
    "print(len(acc))\n",
    "cluster_kmeans4['acc'] = acc\n",
    "cluster_kmeans4.head()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sse[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    l = cluster_kmeans4[cluster_kmeans4.cluster == i]\n",
    "    l_index = cluster_kmeans4[cluster_kmeans4.cluster == i].index\n",
    "    print(l['acc'].mean())\n",
    "    print(len(l_index))\n",
    "    print(\"%%%%%%%%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_kmeans4['acc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.where(0 == cluster_kmeans4[cluster_kmeans4['acc']<0.5]['cluster'])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_kmeans4['acc'][1556]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans4.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_trial = temp.find_n_initial(trial=trial_3,N=4000,good=15,bad=3987)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_loss=good_trial.losses()\n",
    "losses = [abs(i) for i in good_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_loss=trial_3.losses()\n",
    "all_losses = [abs(i) for i in all_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21945"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### histogram the best History sofar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "counts, edges, plot = plt.hist(all_losses, bins=5)\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('N - points')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_equal_percentage_base(trial, percentage, n_bin, plot=True):\n",
    "\n",
    "\n",
    "    losses = trial.losses()\n",
    "    losses = [abs(i) for i in losses]\n",
    "    losses = np.array(losses)\n",
    "    losses_index = np.argsort(losses)\n",
    "\n",
    "\n",
    "    selected_index = []\n",
    "\n",
    "    def select_points(binmember):\n",
    "        if len(binmember) == 0:\n",
    "            return len(binmember)\n",
    "        \n",
    "        binmember = np.array(binmember)\n",
    "        required_number = int((percentage/100) * len(binmember)) \n",
    "\n",
    "        \n",
    "        list_diff=[]\n",
    "        for i,x in enumerate(binmember):\n",
    "            list_diff.append(abs(binmember[i]-binmember.mean()))\n",
    "\n",
    "        list_diff = np.array(list_diff)\n",
    "        indexes = np.argpartition(list_diff,required_number)[:required_number]\n",
    "        print(\"{} selected from this bin\".format(len(indexes)))\n",
    "        \n",
    "        for xx in indexes:\n",
    "            selected_index.append(xx)\n",
    "        return len(binmember)\n",
    "        \n",
    "    out = stats.binned_statistic(losses, statistic=select_points, bins=n_bin, values=losses)\n",
    "\n",
    "    print(\"Number of Selected points is {}\".format(len(selected_index)))\n",
    "    if plot:\n",
    "        plt.hist(losses, bins=n_bin)\n",
    "        plt.xlabel('Accuracy')\n",
    "        plt.ylabel('N - points')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    \n",
    "    # build the new trial\n",
    "    new_trial = []\n",
    "    for i in selected_index:\n",
    "        new_trial.append(trial.trials[i])\n",
    "\n",
    "    empty_trial = Trials()\n",
    "    trial_merged = trials_from_docs(list(empty_trial) + new_trial)\n",
    "\n",
    "    for i, v in enumerate(trial_merged.trials):\n",
    "\n",
    "        need_to_change = trial_merged.trials[i]['tid']\n",
    "\n",
    "        trial_merged.trials[i]['tid'] = i\n",
    "        trial_merged.trials[i]['misc']['tid'] = i\n",
    "        for key in v['misc']['idxs']:\n",
    "            if v['misc']['idxs'][str(key)] == [need_to_change]:\n",
    "                trial_merged.trials[i]['misc']['idxs'][str(key)] = [i]\n",
    "\n",
    "    return trial_merged\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 30, 50, 70, 90])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(10,100,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 selected from this bin\n",
      "13 selected from this bin\n",
      "294 selected from this bin\n",
      "92 selected from this bin\n",
      "1785 selected from this bin\n",
      "Number of Selected points is 2192\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "histogram_equal_percentage_base(trial=trial_3,percentage=10,n_bin=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage=[]\n",
    "for number in counts:\n",
    "    percentage.append((number/21249)*100)\n",
    "percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   86.,   139.,  2949.,   921., 17850.])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = np.array(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_points(a):\n",
    "    a=np.array(a)\n",
    "    print(a.mean())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "stats.binned_statistic(losses, statistic=select_points, bins=5, values=losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(good_trial.losses()).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = temp.vector_builder(good_trial)\n",
    "X = np.array(good_trial)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.47778473091364204"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_trial.trials[290]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i,xx in enumerate(X):\n",
    "    if(xx[0]==0.47778473091364204):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data  # we only take the first two features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "principalComponents = pca.fit_transform(X)\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['component1', 'component2'])\n",
    "a = principalDf.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(a[:,0],a[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "# Data for a three-dimensional line\n",
    "zline = principalDf['component1']\n",
    "xline = principalDf['component2']\n",
    "yline = principalDf['component3']\n",
    "ax.plot3D(xline, yline, zline, 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as sch\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 20\n",
    "fig_size[1] = 8\n",
    "\n",
    "dendegram = sch.dendrogram(sch.linkage(X,method='ward'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc = AgglomerativeClustering(n_clusters=4,affinity='euclidean',linkage='ward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hc = hc.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import somoclu\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "som = somoclu.Somoclu(80,4000, data=X)\n",
    "%time som.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "som.view_component_planes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimalK(data, nrefs=3, maxClusters=15):\n",
    "    \"\"\"\n",
    "    Calculates KMeans optimal K using Gap Statistic from Tibshirani, Walther, Hastie\n",
    "    Params:\n",
    "        data: ndarry of shape (n_samples, n_features)\n",
    "        nrefs: number of sample reference datasets to create\n",
    "        maxClusters: Maximum number of clusters to test for\n",
    "    Returns: (gaps, optimalK)\n",
    "    \"\"\"\n",
    "    gaps = np.zeros((len(range(1, maxClusters)),))\n",
    "    resultsdf = pd.DataFrame({'clusterCount':[], 'gap':[]})\n",
    "    for gap_index, k in enumerate(range(1, maxClusters)):\n",
    "\n",
    "        # Holder for reference dispersion results\n",
    "        refDisps = np.zeros(nrefs)\n",
    "\n",
    "        # For n references, generate random sample and perform kmeans getting resulting dispersion of each loop\n",
    "        for i in range(nrefs):\n",
    "            \n",
    "            # Create new random reference set\n",
    "            randomReference = np.random.random_sample(size=data.shape)\n",
    "            \n",
    "            # Fit to it\n",
    "            km = KMeans(k)\n",
    "            km.fit(randomReference)\n",
    "            \n",
    "            refDisp = km.inertia_\n",
    "            refDisps[i] = refDisp\n",
    "\n",
    "        # Fit cluster to original data and create dispersion\n",
    "        km = KMeans(k)\n",
    "        km.fit(data)\n",
    "        \n",
    "        origDisp = km.inertia_\n",
    "\n",
    "        # Calculate gap statistic\n",
    "        gap = np.log(np.mean(refDisps)) - np.log(origDisp)\n",
    "\n",
    "        # Assign this loop's gap statistic to gaps\n",
    "        gaps[gap_index] = gap\n",
    "        \n",
    "        resultsdf = resultsdf.append({'clusterCount':k, 'gap':gap}, ignore_index=True)\n",
    "\n",
    "    return (gaps.argmax() + 1, resultsdf)  # Plus 1 because index of 0 means 1 cluster is optimal, index 2 = 3 clusters are optimal\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k, gapdf = optimalK(X, nrefs=10, maxClusters=10)\n",
    "print ('Optimal k is: ', k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the best K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# estimate number of clusters with the gap statistic\n",
    "from what_the_cluster.GapStat import GapStat\n",
    "gs = GapStat(clusterer='kmeans',  # an arbitrary clustering algorithm can be provided\n",
    "         cluster_sizes=range(1, 10),\n",
    "         ref_dist='uniform',  # either 'uniform' or 'svd'\n",
    "         B=10)  # number of samples from the reference null distribution\n",
    "\n",
    "gs.fit(X)\n",
    "gs.plot_wcss_curves()\n",
    "gs.plot_gap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Silhouette Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "all_sil_coeff =[]\n",
    "for n_cluster in range(2, 11):\n",
    "    kmeans = KMeans(n_clusters=n_cluster).fit(X)\n",
    "    label = kmeans.labels_\n",
    "    sil_coeff = silhouette_score(X, label, metric='euclidean')\n",
    "    all_sil_coeff.append(sil_coeff)\n",
    "    print(\"For n_clusters={}, The Silhouette Coefficient is {}\".format(n_cluster, sil_coeff))\n",
    "plt.plot(all_sil_coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = 16, 8\n",
    "\n",
    "def draw_ellipse(position, covariance, ax=None, **kwargs):\n",
    "    \"\"\"Draw an ellipse with a given position and covariance\"\"\"\n",
    "    ax = ax or plt.gca()\n",
    "    # Convert covariance to principal axes\n",
    "    if covariance.shape == (2, 2):\n",
    "        U, s, Vt = np.linalg.svd(covariance)\n",
    "        angle = np.degrees(np.arctan2(U[1, 0], U[0, 0]))\n",
    "        width, height = 2 * np.sqrt(s)\n",
    "    else:\n",
    "        angle = 0\n",
    "        width, height = 2 * np.sqrt(covariance)\n",
    "    \n",
    "    # Draw the Ellipse\n",
    "    for nsig in range(1, 4):\n",
    "        ax.add_patch(Ellipse(position, nsig * width, nsig * height,\n",
    "                             angle, **kwargs))\n",
    "        \n",
    "def plot_gmm(gmm, X, label=True, ax=None):\n",
    "    ax = ax or plt.gca()\n",
    "    labels = gmm.fit(X).predict(X)\n",
    "    if label:\n",
    "        ax.scatter(X[:, 0], X[:, 1], c=labels, s=40, cmap='viridis', zorder=2)\n",
    "    else:\n",
    "        ax.scatter(X[:, 0], X[:, 1], s=40, zorder=2)\n",
    "    \n",
    "    w_factor = 0.2 / gmm.weights_.max()\n",
    "    for pos, covar, w in zip(gmm.means_, gmm.covariances_, gmm.weights_):\n",
    "        draw_ellipse(pos, covar, alpha=w * w_factor)\n",
    "    plt.title(\"GMM with %d components\"%len(gmm.means_), fontsize=(20))\n",
    "    plt.xlabel(\"U.A.\")\n",
    "    plt.ylabel(\"U.A.\")\n",
    "def SelBest(arr:list, X:int)->list:\n",
    "    '''\n",
    "    returns the set of X configurations with shorter distance\n",
    "    '''\n",
    "    dx=np.argsort(arr)[:X]\n",
    "    return arr[dx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters=np.arange(2, 10)\n",
    "sils=[]\n",
    "sils_err=[]\n",
    "iterations=20\n",
    "for n in n_clusters:\n",
    "    tmp_sil=[]\n",
    "    for _ in range(iterations):\n",
    "        gmm=GMM(n, n_init=2).fit(embeddings) \n",
    "        labels=gmm.predict(embeddings)\n",
    "        sil=metrics.silhouette_score(embeddings, labels, metric='euclidean')\n",
    "        tmp_sil.append(sil)\n",
    "    val=np.mean(SelBest(np.array(tmp_sil), int(iterations/5)))\n",
    "    err=np.std(tmp_sil)\n",
    "    sils.append(val)\n",
    "    sils_err.append(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(n_clusters, sils, yerr=sils_err)\n",
    "plt.title(\"Silhouette Scores\", fontsize=20)\n",
    "plt.xticks(n_clusters)\n",
    "plt.xlabel(\"N. of clusters\")\n",
    "plt.ylabel(\"Score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BIC Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bics=[]\n",
    "bics_err=[]\n",
    "iterations=20\n",
    "for n in n_clusters:\n",
    "    tmp_bic=[]\n",
    "    for _ in range(iterations):\n",
    "        gmm=GMM(n, n_init=2).fit(embeddings) \n",
    "        \n",
    "        tmp_bic.append(gmm.bic(embeddings))\n",
    "    val=np.mean(SelBest(np.array(tmp_bic), int(iterations/5)))\n",
    "    err=np.std(tmp_bic)\n",
    "    bics.append(val)\n",
    "    bics_err.append(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(n_clusters,bics, yerr=bics_err, label='BIC')\n",
    "plt.title(\"BIC Scores\", fontsize=20)\n",
    "plt.xticks(n_clusters)\n",
    "plt.xlabel(\"N. of clusters\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find the nearst point to centroid in kmeasn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Compute DBSCAN\n",
    "db = DBSCAN(eps=0.3, min_samples=10).fit(X)\n",
    "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True\n",
    "labels = db.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_clusters_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_map = pd.DataFrame()\n",
    "cluster_map['data_index'] = range(0,X.shape[0])\n",
    "cluster_map['cluster'] = db.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(cluster_map['cluster']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = cluster_map.groupby('cluster').count()\n",
    "print(list(types))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selecet_index_base_DBSCAN(X,min_member):\n",
    "    '''\n",
    "    X: np.array\n",
    "    k: number of k in kmeans\n",
    "    min_member: number of sample should take out of each cluster\n",
    "    '''\n",
    "    # Compute DBSCAN\n",
    "    db = DBSCAN(eps=0.3, min_samples=min_member).fit(X)\n",
    "    core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "    core_samples_mask[db.core_sample_indices_] = True\n",
    "    labels = db.labels_\n",
    "\n",
    "\n",
    "    # Number of clusters in labels, ignoring noise if present.\n",
    "    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    n_noise_ = list(labels).count(-1)\n",
    "    \n",
    "    print (\"Number of Cluster is {}\".format(print(n_clusters_)))\n",
    "\n",
    "\n",
    "    cluster_map = pd.DataFrame()\n",
    "    cluster_map['data_index'] = range(0,X.shape[0])\n",
    "    cluster_map['cluster'] = db.labels_\n",
    "\n",
    "    selected_index=[]\n",
    "    for i in list(set(cluster_map['cluster'])):\n",
    "        l = cluster_map[cluster_map.cluster == i].index\n",
    "        if len(l)<=min_member:\n",
    "            selected_index = list(l)+ list(selected_index)\n",
    "        else:\n",
    "            sampling = random.choices(l, k=min_member)\n",
    "            selected_index = list(selected_index) + list(sampling)\n",
    "        l=[]\n",
    "    \n",
    "    return selected_index\n",
    "    \n",
    "selected_index = selecet_index_base_DBSCAN(X,min_member=10)  \n",
    "print(len(selected_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial3_basedDBSACN = temp.specialindex_trial_builder(trial_3,selected_index)\n",
    "print(len(trial3_basedDBSACN.trials))\n",
    "\n",
    "#save the result\n",
    "pickle.dump(trial3_basedDBSACN, open('/home/dfki/Desktop/Thesis/hyperopt/result_openml/mylaptop/3/automatic/new/trials/trial3_940in_basedDBSACN_k=93.p', 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_3 = 79.84\n",
    "dataset_3_history = 83.99 #21249 history \n",
    "\n",
    "dataset_3_kmeansopenml_history = 71.90 #153 history \n",
    "dataset_3_153_random = 77.49 #5 times run\n",
    "\n",
    "dataset_3_kmeanshyperopt_history =81.74 # 240 history\n",
    "dataset_3_240random = 75.39 #5 times run \n",
    "\n",
    "dataframe = {'Dataset':[3],\n",
    "             'Null_History':[dataset_3],\n",
    "             'With_full_History':[dataset_3_history],\n",
    "             'kmeans_openml_History':[dataset_3_kmeansopenml_history],\n",
    "             'kmeans_openml_random':[dataset_3_153_random],\n",
    "             'kmeans_hyperopt_History':[dataset_3_kmeanshyperopt_history],\n",
    "             'kmeans_hyperopt_random':[dataset_3_240random]\n",
    "             \n",
    "            }\n",
    "\n",
    "dataframe_1 = pd.DataFrame(dataframe)\n",
    "\n",
    "dataframe_2 = pd.melt(dataframe_1, id_vars=\"Dataset\", var_name=\"Approaches\", value_name=\"Avg_Accuracies\")\n",
    "dataframe_2.head()\n",
    "\n",
    "sns.set(font_scale=1.5,style='whitegrid')\n",
    "# sns.set_context(\"talk\",font_scale=1.4,rc={'figure.figsize':(11.7,15)} )\n",
    "\n",
    "g= sns.catplot(x='Dataset', y='Avg_Accuracies', hue='Approaches', data=dataframe_2, kind='bar',aspect=2)\n",
    "g.set(ylim=(60,95))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the best epsilon for DBscan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import DBSCAN\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = NearestNeighbors(n_neighbors=2)\n",
    "nbrs = neigh.fit(X)\n",
    "distances, indices = nbrs.kneighbors(X)\n",
    "\n",
    "distances = np.sort(distances, axis=0)\n",
    "distances = distances[:,1]\n",
    "\n",
    "# print(distances)\n",
    "# print(indices)\n",
    "plt.plot(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = distances[np.where(np.sort(distances)<25)]\n",
    "plt.plot(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=1, random_state=0).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center_a = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "s = [20, 15, 27, 30]\n",
    "heapq.nsmallest(2,[i for i, k in enumerate(s)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_a=[]\n",
    "for row in X:\n",
    "    distance_a.append(scipy.spatial.distance.euclidean(center_a, row))\n",
    "np.argsort(distance_a)[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(distance_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "A = np.array([1, 7, 9, 2, 0.1, 17, 17, 1.5])\n",
    "np.argsort(A)[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def cluster_DBSCAN(X_1,min_member=20):\n",
    "    '''\n",
    "    X: np.array\n",
    "    k: number of k in kmeans\n",
    "    min_member: number of sample should take out of each cluster\n",
    "    '''\n",
    "    # Compute DBSCAN\n",
    "    db = DBSCAN(eps=50, min_samples=min_member).fit(X_1)\n",
    "    core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "    core_samples_mask[db.core_sample_indices_] = True\n",
    "    labels = db.labels_\n",
    "\n",
    "\n",
    "    # Number of clusters in labels, ignoring noise if present.\n",
    "    #n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    \n",
    "    #keep the outlier\n",
    "    n_clusters_ = len(set(labels))\n",
    "    n_noise_ = list(labels).count(-1)\n",
    "   \n",
    "    print (\"N cluster is {}\".format(n_clusters_))\n",
    "    return n_clusters_\n",
    "\n",
    "\n",
    "\n",
    "def objective(args):\n",
    "    a,b,c,d,e = args\n",
    "    \n",
    "    print(a,b,c,d,e)\n",
    "    print(\"-------------\")\n",
    "    N_a = int(a * 86)\n",
    "    N_b = int(b * 139)\n",
    "    N_c = int(c * 2519)\n",
    "    N_d = int(d * 522)\n",
    "    N_e = int(e * 17983)\n",
    "    \n",
    "    list_a = list(np.where((X[:,0]>0) & (X[:,0]<0.2))[0])\n",
    "    list_b = list(np.where((X[:,0]>0.2) & (X[:,0]<0.4))[0])\n",
    "    list_c = list(np.where((X[:,0]>0.4) & (X[:,0]<0.6))[0])\n",
    "    list_d = list(np.where((X[:,0]>0.6) & (X[:,0]<0.8))[0])\n",
    "    list_e = list(np.where((X[:,0]>0.8) & (X[:,0]<0.999))[0])\n",
    "    \n",
    "#     print(len(list_a),len(list_b),len(list_c),len(list_d),len(list_e))\n",
    "    \n",
    "    random.seed(0)\n",
    "\n",
    "\n",
    "    def sampling1(list_a,N_a):      \n",
    "        X_a= X[list_a,:]\n",
    "        kmeans_a = KMeans(n_clusters=1, random_state=0).fit(X_a)\n",
    "        center_a = kmeans_a.cluster_centers_\n",
    "        distance_a=[]\n",
    "        for rows in X_a:\n",
    "            distance_a.append(scipy.spatial.distance.euclidean(center_a, rows))\n",
    "        sampling_a = np.argsort(distance_a)[:N_a]\n",
    "        return sampling_a\n",
    "    \n",
    "    sampling_a = sampling1(list_a,min(N_a,len(list_a)))\n",
    "    sampling_b = sampling1(list_b,min(N_b,len(list_b)))\n",
    "    sampling_c = sampling1(list_c,min(N_c,len(list_c)))\n",
    "    sampling_d = sampling1(list_d,min(N_d,len(list_d)))\n",
    "    sampling_e = sampling1(list_e,min(N_e,len(list_e)))\n",
    "    \n",
    "    \n",
    "    sampling_all = list(sampling_a)+list(sampling_b)+list(sampling_c)+list(sampling_d)+list(sampling_e)\n",
    "\n",
    "    \n",
    "    new_x = X[sampling_all,:]\n",
    "    \n",
    "    print(new_x.shape)\n",
    "    \n",
    "    n_cluster = cluster_DBSCAN(new_x)\n",
    "    \n",
    "    Deduction = n_cluster/len(sampling_all)\n",
    "    \n",
    "    print(\"Deduction is {}\".format(Deduction))\n",
    "    print(\"^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\")\n",
    "    \n",
    "    \n",
    "    return {'loss': -Deduction, 'status': STATUS_OK,'index':sampling_all }\n",
    "\n",
    "\n",
    "space  = [hp.uniform('a',0,1),\n",
    "         hp.uniform('b',0,1),\n",
    "         hp.uniform('c',0,1),\n",
    "         hp.uniform('d',0,1),\n",
    "         hp.uniform('e',0,1)]\n",
    "\n",
    "\n",
    "trial = Trials()\n",
    "\n",
    "\n",
    "best,trials_new = fmin(objective,\n",
    "    space=space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=100,\n",
    "    trials=trial,\n",
    "    rstate=np.random.RandomState(10),)\n",
    "\n",
    "print(best)\n",
    "best_indexes = trials_new.best_trial['result']['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(best_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_base_maxkasr = temp.sepecialindex_trial_builder(trial_3,best_indexes)\n",
    "pickle.dump(trial_base_maxkasr, open('/home/dfki/Desktop/Thesis/hyperopt/result_openml/mylaptop/3/automatic/new/trials/trial_base_maxkasr1049.p','wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iteration in list(np.arange(2000,11000,2000)):\n",
    "    trials_1 = vector.trial_builder_kmeans(trial_3,num_clusters=iteration)\n",
    "    print(trials_1.trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cluster_map = pd.DataFrame()\n",
    "cluster_map['data_index'] = []\n",
    "\n",
    "cluster_map.loc[0,'data_index'] = 0\n",
    "\n",
    "cluster_map.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "iris = load_iris()\n",
    "\n",
    "X = pd.DataFrame(iris.data, columns=iris['feature_names'])\n",
    "\n",
    "\n",
    "sse = []\n",
    "list_k = list(range(2,10))\n",
    "cluster_map = pd.DataFrame()\n",
    "cluster_map['data_index'] = range(0,X.shape[0])\n",
    "\n",
    "for k in list_k:\n",
    "    km = KMeans(n_clusters=k)\n",
    "    km.fit(X)\n",
    "    sse.append(km.inertia_)\n",
    "    \n",
    "    cluster_map['cluster_{}'.format(k)] = km.labels_\n",
    "#     print(cluster_map.groupby('cluster_{}'.format(k)).count())\n",
    "#     print(\"---------------------------------------\")\n",
    "\n",
    "# Plot sse against k\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(list_k, sse, '-o')\n",
    "plt.xlabel(r'Number of clusters *k*')\n",
    "plt.ylabel('Sum of squared distance')\n",
    "plt.grid(True)\n",
    "print(sse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "iris = load_iris()\n",
    "X = pd.DataFrame(iris.data, columns=iris['feature_names'])\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "sse = []\n",
    "list_k = list(range(2,10))\n",
    "cluster_map = pd.DataFrame()\n",
    "cluster_map['data_index'] = range(0,X.shape[0])\n",
    "\n",
    "for k in list_k:\n",
    "    km = KMeans(n_clusters=k)\n",
    "    km.fit(X)\n",
    "    sse.append(km.inertia_)\n",
    "    \n",
    "    cluster_map['cluster_{}'.format(k)] = km.labels_\n",
    "#     print(cluster_map.groupby('cluster_{}'.format(k)).count())\n",
    "#     print(\"---------------------------------------\")\n",
    "\n",
    "# Plot sse against k\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(list_k, sse, '-o')\n",
    "plt.xlabel(r'Number of clusters *k*')\n",
    "plt.ylabel('Sum of squared distance')\n",
    "plt.grid(True)\n",
    "print(sse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withoutscaling = [152.34795176035792, 78.85144142614601, 57.228473214285714, 46.44618205128205, 41.704424470266574, 34.40900974025974, 30.01588095238096, 27.894012189564823]\n",
    "scaling = [222.36170496502308, 140.0327527742865, 114.30480331856761, 90.80759161913358, 81.72775255799205, 71.81371300822669, 62.647183903468985, 54.29894572818739]\n",
    "\n",
    "for x,y in zip(withoutscaling,scaling):\n",
    "    print(x/y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features.\n",
    "y = iris.target\n",
    "\n",
    "\n",
    "# To getter a better understanding of interaction of the dimensions\n",
    "# plot the first three PCA dimensions\n",
    "fig = plt.figure(1, figsize=(8, 6))\n",
    "ax = Axes3D(fig, elev=-150, azim=110)\n",
    "X_reduced = PCA(n_components=3).fit_transform(iris.data)\n",
    "ax.scatter(X_reduced[:, 0], X_reduced[:, 1], X_reduced[:, 2], c=y,\n",
    "           cmap=plt.cm.Set1, edgecolor='k', s=40)\n",
    "ax.set_title(\"First three PCA directions\")\n",
    "ax.set_xlabel(\"1st eigenvector\")\n",
    "ax.w_xaxis.set_ticklabels([])\n",
    "ax.set_ylabel(\"2nd eigenvector\")\n",
    "ax.w_yaxis.set_ticklabels([])\n",
    "ax.set_zlabel(\"3rd eigenvector\")\n",
    "ax.w_zaxis.set_ticklabels([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features.\n",
    "X = StandardScaler().fit_transform(X)\n",
    "y = iris.target\n",
    "\n",
    "\n",
    "\n",
    "# To getter a better understanding of interaction of the dimensions\n",
    "# plot the first three PCA dimensions\n",
    "XX = iris.data\n",
    "# XX = StandardScaler().fit_transform(XX)\n",
    "fig = plt.figure(1, figsize=(8, 6))\n",
    "ax = Axes3D(fig, elev=-150, azim=110)\n",
    "\n",
    "\n",
    "X_reduced = PCA(n_components=2).fit_transform(XX)\n",
    "\n",
    "ax.scatter(X_reduced[:,0],X_reduced[:,1])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= np.array([[None,2,None],[3,4,None],[None,None,None]])\n",
    "df = pd.DataFrame(a)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis='columns',how='all')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in X:\n",
    "    if None in X:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(a[:,:]==np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    df[col].fillna(df[col].mean(),inplace=True)\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nan == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To calculate mean use imputer class\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values= None, strategy='mean')\n",
    "imputer = imputer.fit(X[:, 1:3])\n",
    "X[:, 1:3] = imputer.transform(X[:, 1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d={'A':2,'V':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'a'in [str(i).lower() for i in d.keys()]:\n",
    "    print('true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1575415510478908\n",
    "trial_128 = pickle.load(open(\"/home/dfki/Desktop/Thesis/hyperopt/result_openml/mylaptop/3/automatic/new/trials/trial128_k=8.p\", \"rb\"))\n",
    "\n",
    "trial_128.trials[18]['misc']['vals']['decisiontreeclassifier__max_depth'] =[0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the result\n",
    "pickle.dump(trial_128, open('/home/dfki/Desktop/Thesis/hyperopt/result_openml/mylaptop/3/automatic/new/trials/trial128_k=8.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_3.trials[1230]['misc']['vals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (21945):\n",
    "    for k,v in trial_3.trials[i]['misc']['vals'].items():\n",
    "        if len(v) !=0:\n",
    "            if type(v[0]) ==str:\n",
    "                print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_index = range(0,1225)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial3_basedkmeasn = temp.specialindex_trial_builder(trial_3,selected_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#save the result\n",
    "pickle.dump(trial3_basedkmeasn, open('/home/dfki/Desktop/Thesis/openml_test/pickel_files/3/trial_3_new1.p', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
